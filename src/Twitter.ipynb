{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter RecSys Challenge 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from twitter_preproc import twitter_preproc\n",
    "\n",
    "#spark = SparkSession.builder.appName(\"ChiSquareSpark\").getOrCreate()\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Pipeline\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproc Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting twitter_preproc.py\n"
     ]
    }
   ],
   "source": [
    "%%file twitter_preproc.py\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.ml.feature import RegexTokenizer, OneHotEncoderEstimator, StringIndexer\n",
    "\n",
    "class twitter_preproc:\n",
    "    \n",
    "    def __init__(self, spark:SparkSession, sc:SparkContext, inputFile:str, seed:int=123, MF:bool=False):\n",
    "        self.sc = sc\n",
    "        #inputRDD = sc.textFile(inputFile)\n",
    "        #self.inputData = spark.read.option(\"sep\", \"\\x01\").csv(inputFile)\n",
    "        SCHEMA = StructType([\n",
    "                StructField(\"text_tokens\", StringType()),\n",
    "                StructField(\"hashtags\", StringType()),\n",
    "                StructField(\"tweet_id\", StringType()),\n",
    "                StructField(\"present_media\", StringType()),\n",
    "                StructField(\"present_links\", StringType()),\n",
    "                StructField(\"present_domains\", StringType()),\n",
    "                StructField(\"tweet_type\", StringType()),\n",
    "                StructField(\"language\", StringType()),\n",
    "                StructField(\"tweet_timestamp\", LongType()),\n",
    "                StructField(\"engaged_with_user_id\", StringType()),\n",
    "                StructField(\"engaged_with_user_follower_count\", LongType()),\n",
    "                StructField(\"engaged_with_user_following_count\", LongType()),\n",
    "                StructField(\"engaged_with_user_is_verified\", BooleanType()),\n",
    "                StructField(\"engaged_with_user_account_creation\", LongType()),\n",
    "                StructField(\"engaging_user_id\", StringType()),\n",
    "                StructField(\"engaging_user_follower_count\", LongType()),\n",
    "                StructField(\"engaging_user_following_count\", LongType()),\n",
    "                StructField(\"engaging_user_is_verified\", BooleanType()),\n",
    "                StructField(\"engaging_user_account_creation\", LongType()),\n",
    "                StructField(\"engaged_follows_engaging\", BooleanType()),\n",
    "                StructField(\"reply_timestamp\", LongType()),\n",
    "                StructField(\"retweet_timestamp\", LongType()),\n",
    "                StructField(\"retweet_with_comment_timestamp\", LongType()),\n",
    "                StructField(\"like_timestamp\", LongType())       \n",
    "            ])\n",
    "        self.inputData = spark.read.csv(path=inputFile, sep=\"\\x01\", header=False, schema=SCHEMA)\n",
    "        if MF:\n",
    "            self._preprocessMF()\n",
    "        else:\n",
    "            self._preprocess(seed)\n",
    "        #self.inputData = spark.createDataFrame(inputRDD, sep=\"\\x01\", schema=SCHEMA)    \n",
    "    \n",
    "    def getDF(self):\n",
    "        return self.outputDF\n",
    "    \n",
    "    def _preprocessMF(self):\n",
    "        outputDF = self.inputData\n",
    "        \n",
    "        self.outputDF = outputDF.select([\"tweet_id\",\"engaging_user_id\",\"engaged_with_user_id\",\n",
    "                                    \"retweet_timestamp\",\"reply_timestamp\",\n",
    "                                    \"retweet_with_comment_timestamp\",\"like_timestamp\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _preprocess(self, seed):\n",
    "        \n",
    "        outputDF = self.inputData\n",
    "        \n",
    "        # Drop unnecessary cols\n",
    "        ### drop ids for classification\n",
    "        outputDF = outputDF.drop(\"tweet_id\").drop(\"engaged_user_id\").drop(\"engaged_with_user_id\")\\\n",
    "                    .drop(\"present_links\").drop(\"present_domains\")\n",
    "        \n",
    "        # Split the text tokens to valid format\n",
    "        regexTokenizer = RegexTokenizer(inputCol=\"text_tokens\",outputCol=\"vector\", pattern=\"\\t\")\n",
    "        outputDF = regexTokenizer.transform(outputDF)\n",
    "        outputDF = outputDF.drop(\"text_tokens\").withColumnRenamed(\"vector\", \"text_tokens\")\n",
    "        \n",
    "        regexTokenizer = RegexTokenizer(inputCol=\"present_media\", outputCol=\"media_list\")\n",
    "        outputDF = regexTokenizer.transform(outputDF.fillna(\"none\", subset=[\"present_media\"]))\n",
    "        outputDF = outputDF.drop(\"present_media\").withColumnRenamed(\"media_list\", \"present_media\")\n",
    "        outputDF = outputDF.withColumn(\"present_media2\", outputDF[\"present_media\"].cast(StringType()))\n",
    "        outputDF = outputDF.drop(\"present_media\").withColumnRenamed(\"present_media2\", \"present_media\")\n",
    "\n",
    "        # OneHotEncode tweet_type\n",
    "        ## TODO: user_id, engaged_user_id, ...\n",
    "        indexer = StringIndexer(inputCol=\"tweet_type\", outputCol=\"tweet_type_id\")\n",
    "        outputDF = indexer.fit(outputDF).transform(outputDF)\n",
    "        indexer = StringIndexer(inputCol=\"present_media\", outputCol=\"present_media_id\")\n",
    "        outputDF = indexer.fit(outputDF).transform(outputDF)\n",
    "        indexer = StringIndexer(inputCol=\"language\", outputCol=\"language_id\")\n",
    "        outputDF = indexer.fit(outputDF).transform(outputDF)\n",
    "        \n",
    "        # onehot\n",
    "        encoder = OneHotEncoderEstimator(inputCols=[\"tweet_type_id\", \"present_media_id\", \"language_id\"],\n",
    "                                         outputCols=[\"tweet_type_onehot\", \"present_media_onehot\", \"language_onehot\"])\n",
    "        model = encoder.fit(outputDF)\n",
    "        outputDF = model.transform(outputDF)\n",
    "        \n",
    "        # for explainability safe this\n",
    "        self.explainOneHotDF = outputDF.select(\"tweet_type\", \"tweet_type_id\", \"tweet_type_onehot\",\n",
    "                                              \"present_media\", \"present_media_id\", \"present_media_onehot\",\n",
    "                                               \"language\", \"language_id\", \"language_onehot\"\n",
    "                                              )\n",
    "        # make label columns binary\n",
    "        outputDF = outputDF.withColumn(\"like\", when(outputDF[\"like_timestamp\"].isNull(), 0).otherwise(1))\n",
    "        outputDF = outputDF.withColumn(\"retweet\", when(outputDF[\"retweet_timestamp\"].isNull(), 0).otherwise(1))\n",
    "        outputDF = outputDF.withColumn(\"reply\", when(outputDF[\"reply_timestamp\"].isNull(), 0).otherwise(1))\n",
    "        outputDF = outputDF.withColumn(\"retweet_comment\", when(outputDF[\"retweet_with_comment_timestamp\"].isNull(), 0).otherwise(1))\n",
    "        \n",
    "        # drop intermediate columns\n",
    "        outputDF = outputDF.drop(*[\"like_timestamp\",\"retweet_timestamp\",\"reply_timestamp\",\n",
    "                                  \"retweet_with_comment_timestamp\",\"tweet_type\",\"tweet_type_id\",\n",
    "                                 \"language\",\"language_id\",\"present_media\",\"present_media_id\"])\n",
    "        \n",
    "        # TODO: Train/Test split and Scaling\n",
    "        \n",
    "        # might not need\n",
    "        # transform boolean to 0-1 column... first one has to change the type in the schema though \n",
    "        #data = data.select(\"engaging_user_is_verified\", \"engaged_with_user_is_verified\", \"engaged_follows_engaging\")\\\n",
    "        #    .replace([\"false\",\"true\"], [\"0\",\"1\"]).show()\n",
    "        \n",
    "        \n",
    "        self.outputDF = outputDF\n",
    "        \n",
    "    '''\n",
    "        returns small dataframe that explains the values of the oneHotEncoder step, this might be needed\n",
    "        for mapping the encodings back to the original values\n",
    "    '''    \n",
    "    def explainOneHot(self):\n",
    "        return self.explainOneHotDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = \"///user/e11920598/traintweet_1000.tsv\"\n",
    "train = \"///tmp/traintweet_1000.tsv\"\n",
    "#train = \"///user/pknees/RSC20/training.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "column_names = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\\\n",
    "                \"tweet_type\", \"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\\\n",
    "               \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\", \"engaged_with_user_account_creation\",\\\n",
    "               \"engaging_user_id\", \"engaging_user_follower_count\", \"engaging_user_following_count\", \"engaging_user_is_verified\",\\\n",
    "               \"engaging_user_account_creation\", \"engaged_follows_engaging\", \"reply_timestamp\", \"retweet_timestamp\", \"retweet_with_comment_timestamp\", \"like_timestamp\"]\n",
    "\n",
    "SCHEMA = StructType([\n",
    "                StructField(\"text_tokens\", StringType()),\n",
    "                StructField(\"hashtags\", StringType()),\n",
    "                StructField(\"tweet_id\", StringType()),\n",
    "                StructField(\"present_media\", StringType()),\n",
    "                StructField(\"present_links\", StringType()),\n",
    "                StructField(\"present_domains\", StringType()),\n",
    "                StructField(\"tweet_type\", StringType()),\n",
    "                StructField(\"language\", StringType()),\n",
    "                StructField(\"tweet_timestamp\", LongType()),\n",
    "                StructField(\"engaged_with_user_id\", StringType()),\n",
    "                StructField(\"engaged_with_user_follower_count\", LongType()),\n",
    "                StructField(\"engaged_with_user_following_count\", LongType()),\n",
    "                StructField(\"engaged_with_user_is_verified\", BooleanType()),\n",
    "                StructField(\"engaged_with_user_account_creation\", LongType()),\n",
    "                StructField(\"engaging_user_id\", StringType()),\n",
    "                StructField(\"engaging_user_follower_count\", LongType()),\n",
    "                StructField(\"engaging_user_following_count\", LongType()),\n",
    "                StructField(\"engaging_user_is_verified\", BooleanType()),\n",
    "                StructField(\"engaging_user_account_creation\", LongType()),\n",
    "                StructField(\"engaged_follows_engaging\", BooleanType()),\n",
    "                StructField(\"reply_timestamp\", LongType()),\n",
    "                StructField(\"retweet_timestamp\", LongType()),\n",
    "                StructField(\"retweet_with_comment_timestamp\", LongType()),\n",
    "                StructField(\"like_timestamp\", LongType())       \n",
    "                                ])\n",
    "\n",
    "len(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter_preproc\n",
    "import importlib\n",
    "importlib.reload(twitter_preproc)\n",
    "from twitter_preproc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----------------+---------------+------------------------------+--------------+\n",
      "|            tweet_id|    engaging_user_id|engaged_with_user_id|retweet_timestamp|reply_timestamp|retweet_with_comment_timestamp|like_timestamp|\n",
      "+--------------------+--------------------+--------------------+-----------------+---------------+------------------------------+--------------+\n",
      "|E7D6C5094767223F6...|00000776B07587ECA...|D557B03872EF8986F...|             null|           null|                          null|          null|\n",
      "|129F4A868712BA2B9...|00000B85AAF7DE172...|424822AC982CE0E89...|       1581497559|           null|                          null|    1581497622|\n",
      "|04C6C2175852CDBBC...|00000E0C9B364891C...|1EC14E26417AA9260...|             null|           null|                          null|    1581060554|\n",
      "|168157826315514C1...|00000F04EEDBCF3E1...|9B9595B6FEB8948BD...|             null|           null|                          null|    1581328518|\n",
      "|B3E3673782A69D9D8...|000010088197DA00D...|525DC99B7CB8F1AC4...|             null|           null|                          null|    1580957807|\n",
      "+--------------------+--------------------+--------------------+-----------------+---------------+------------------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>engaging_user_id</th>\n",
       "      <th>engaged_with_user_id</th>\n",
       "      <th>retweet_timestamp</th>\n",
       "      <th>reply_timestamp</th>\n",
       "      <th>retweet_with_comment_timestamp</th>\n",
       "      <th>like_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E7D6C5094767223F6F8789A87A1937AB</td>\n",
       "      <td>00000776B07587ECA9717BFC301F2D6E</td>\n",
       "      <td>D557B03872EF8986F7F4426AE094B2FE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129F4A868712BA2B98D31AF98C3066E4</td>\n",
       "      <td>00000B85AAF7DE172876FD96718C4469</td>\n",
       "      <td>424822AC982CE0E8965506C63B44EC12</td>\n",
       "      <td>1.581498e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581498e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04C6C2175852CDBBC23B2446C7E7C22D</td>\n",
       "      <td>00000E0C9B364891CDE89ECFC54771DE</td>\n",
       "      <td>1EC14E26417AA926095530AC591BA9CE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581061e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168157826315514C120494D4DF8E6216</td>\n",
       "      <td>00000F04EEDBCF3E1FB9A1948BF353B6</td>\n",
       "      <td>9B9595B6FEB8948BDDF0D222F27E0118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581329e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B3E3673782A69D9D8A45D3B222F0B073</td>\n",
       "      <td>000010088197DA00D659853E06935B3E</td>\n",
       "      <td>525DC99B7CB8F1AC4AD3E66C53FA38E0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.580958e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AB21A06B694D637075F1EA4F89A05197</td>\n",
       "      <td>000012A6D58B300B1B4098C86223F76E</td>\n",
       "      <td>7E1E2FAD93219D0247BDBE451AB343E9</td>\n",
       "      <td>1.581347e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581347e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>166C053A658691172A7A3CB20D8FB614</td>\n",
       "      <td>000012D4971A83624EF9C6711AE5167D</td>\n",
       "      <td>A0FD6DF4B4FBF62949708CDB97CC8124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581009e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C6016D70FDDAF88BB64B00600B48F788</td>\n",
       "      <td>000013E6563760E3916215D42BE0D406</td>\n",
       "      <td>629A622B84E4C67FAB56DCF0DBD785AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>293740496A195D5B20DBE00C3AEFFF17</td>\n",
       "      <td>00001607209C5774DF9207A2AC0EED5F</td>\n",
       "      <td>AD86A376FA5F26E67263D5FCA8A5BD59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581009e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3D89E8BE2E330DA8DD754D58EA07E824</td>\n",
       "      <td>0000170273D2530A0DF580401CC32AE0</td>\n",
       "      <td>2F236A7D11ECDAF1FC472E9ACC32AE6B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>311EDE393CEBB5E880F5B3A96A69AA94</td>\n",
       "      <td>00001F56CDCF81D2EF635B3C0EDE57EB</td>\n",
       "      <td>85A39142470D65A77BB9E86B054AD321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581190e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B9C4540F4798A61C1F17CEB3AE369735</td>\n",
       "      <td>00002086C1D5C05ADE95E1C60FAF71FD</td>\n",
       "      <td>0C89F01A8644F9B685BF2225F00EF34B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EC2126D5DB025A6C66BC24A5596EC475</td>\n",
       "      <td>00002086C1D5C05ADE95E1C60FAF71FD</td>\n",
       "      <td>46097861C196B25F2C56606CD32AE14C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581045e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10932CB9E641857BACF9A49D267A8E98</td>\n",
       "      <td>000024E52825D248DDAB9884DC0BD758</td>\n",
       "      <td>618642C3684BC6B65F905C289D1F376F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581375e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>86E049967C94CF82BA9EB17A2EE4F3CE</td>\n",
       "      <td>000025CDC48B25D9888C6640DE433FE9</td>\n",
       "      <td>49D04A274A357E3039E1DF0F78E2975F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581064e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>222EF495AA79DCCC3F32AB9754E9F173</td>\n",
       "      <td>000026C296F4693A6196F90ABAF80FB6</td>\n",
       "      <td>162984295C1BCFF55D7977B9ADA50AD8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9CF609C0D9D099F7C09B52976F5029F7</td>\n",
       "      <td>0000288C66B7563CB98736F96894D9DC</td>\n",
       "      <td>A702303ED1A25C6DD1393BC0CCABF94A</td>\n",
       "      <td>1.581018e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581018e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6601197539548AAD5C9CB9FCD162A5C7</td>\n",
       "      <td>00002C99ACC8931540C190542549BFE0</td>\n",
       "      <td>0FACF6DB63422FC388A2BB4AA1585AB2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B72C9FD782AF79BA56755410E3C617FC</td>\n",
       "      <td>000030DA986805A0B204966360B8AABB</td>\n",
       "      <td>0D01AD1116E22830152CC5FC78CE952D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C33F498C0F3FE07667B08B834A2FF474</td>\n",
       "      <td>00003B622698D49D3868B01E557FE4E6</td>\n",
       "      <td>5B8C4D92F1AE859A2FD69BB405B03347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581260e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35359883026EF6D9A31F6C962517A15D</td>\n",
       "      <td>000043D9A730DF47697D0750F509B56A</td>\n",
       "      <td>418D921524B4A26261D5F24586CCEDD7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581369e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C95D525FFA8A789ABBA005B9F7BE7174</td>\n",
       "      <td>000043D9A730DF47697D0750F509B56A</td>\n",
       "      <td>9586F04FF09A614BAE30367575053EC4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.580963e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3C21DCFB8E3FEC1CB3D2BFB413A78220</td>\n",
       "      <td>000046C8606F1C3F5A7296222C88084B</td>\n",
       "      <td>D1AA2C85FA644D64346EDD88470525F2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>C83B3441704D4E6172B86CEF3F66845C</td>\n",
       "      <td>00004DF6D6CAB6361EDF8FDE86365ECE</td>\n",
       "      <td>5611A5DB21B6C40C8E3848A4DECFBB24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>42E7832DAB2B068F63B32B6AD85B3F9D</td>\n",
       "      <td>0000510EC3AFC6F9FB8E411852A84877</td>\n",
       "      <td>24F43670B7EF0441CCF800C6B77403BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>C281F4EF6011EFC61BDE3E96216C0A6A</td>\n",
       "      <td>0000510EC3AFC6F9FB8E411852A84877</td>\n",
       "      <td>1216DCF3AF02393B3139C17C28DDDE02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581191e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>C7FB1313DB6D1013282343FFA2AF41FD</td>\n",
       "      <td>0000581864A04C34E289F984EBD20562</td>\n",
       "      <td>E4B09E5CE7BC5D9FB753CDFCF63ACCC0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581548e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28D9CAE78D1F3E9877A9559757D57293</td>\n",
       "      <td>00005B5734CD2CB88CBD541ADEBA0F4F</td>\n",
       "      <td>5A6DCA175E07A222854B7F115C50A3B8</td>\n",
       "      <td>1.580956e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.580956e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>558CAF543304741E670682E4F6CDA1CC</td>\n",
       "      <td>00005B5734CD2CB88CBD541ADEBA0F4F</td>\n",
       "      <td>8397BF026AF4CD632EBB10441B55A22F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>D2F0691D4B7D3933824640F6AED9D308</td>\n",
       "      <td>00005BD9676C7C12A80E686070A180BD</td>\n",
       "      <td>758F32F4069006B21E15EA41BC9EBCEA</td>\n",
       "      <td>1.581220e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>2DF672498994C4F3217A3E536D5B3DEB</td>\n",
       "      <td>000C325ED4406815ED6D0A01F4A022DE</td>\n",
       "      <td>C11B1575C2D534C0E848F07645392B79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>B0FAE386FC61AFACE3558DB8F25915AC</td>\n",
       "      <td>000C327DF907A4C7E8657067AF2E956E</td>\n",
       "      <td>0E8ADEAB18E9E77C25732091412CF4E7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>1F75C1A9ED7009EB5E19791C3109E3AF</td>\n",
       "      <td>000C342ECA70A84E597B8F96C0CC255A</td>\n",
       "      <td>33347DECF6D85A55B6F3466FCBF33C3E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581520e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>9E5221F9ADF15DC8D7E41E5B1144A5D3</td>\n",
       "      <td>000C342ECA70A84E597B8F96C0CC255A</td>\n",
       "      <td>C1CC7182933A775CCE50459B5ECBA354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>5E51F328A948CAAFE94D1AC18529A022</td>\n",
       "      <td>000C3830AD0EDE399D0053FB415F81BE</td>\n",
       "      <td>ED0BEE31DC4C4D5BB9204FB738F5235F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>C283BA903523D54A5BBA8B32595A50B4</td>\n",
       "      <td>000C3EF37A9E9E4F389BE839A806B506</td>\n",
       "      <td>5DFE3006923CC533F49745879C1AA0AD</td>\n",
       "      <td>1.581028e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581028e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>7A7229B71FCBA2E78DA395B5F43EE2C5</td>\n",
       "      <td>000C40888D533376F6C7CEC626C48496</td>\n",
       "      <td>4A39C95294F157A005618CEC35CFEDBB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>844C05347C6E3D9B413E6C4D846FDF88</td>\n",
       "      <td>000C40888D533376F6C7CEC626C48496</td>\n",
       "      <td>31EC136527B50D20155FE3745043554D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581140e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>90649352FDF0B954B99D228D1B2F87BC</td>\n",
       "      <td>000C40888D533376F6C7CEC626C48496</td>\n",
       "      <td>9DADDD754358BC15F6CCC7FA44000DA9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>9BB764177047DEFB11A8BEA281E31A27</td>\n",
       "      <td>000C47CADA1342AE252E9CA346DA1EC6</td>\n",
       "      <td>4CCF7B73021DC0212539A569B83199E7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>DA5B79AC4D0C4007D953E5122F818CA4</td>\n",
       "      <td>000C48903A26C8EDAE2FDC770D83F194</td>\n",
       "      <td>566A6275D7315EAE052ABB177CDFCA60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581430e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>16F93A7AB2618E7EDB1F2A17826EB41C</td>\n",
       "      <td>000C49C5EF6A8C7E9BFA13D19474ED32</td>\n",
       "      <td>35B5BC9DAE87F4F5AD9C4636F8718E27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>FB84B4A226894A7022A2FB4052DBFE43</td>\n",
       "      <td>000C49C5EF6A8C7E9BFA13D19474ED32</td>\n",
       "      <td>75CD9CE5D7F26B532F31CDA3027E3509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>4304C651D4A573409A724B112B2D65BE</td>\n",
       "      <td>000C4DAD25C18E2B1E1644F7C4BD9210</td>\n",
       "      <td>88E9D79DF89B1118C6C52B8791842318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581423e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>100A5AC9ED4FD3833B6BBFC0B0A4F6EB</td>\n",
       "      <td>000C4F1D0B27F9D985774F6F4976F3E7</td>\n",
       "      <td>71BBC322E6D40D590715CA8814C72E0A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>37D5378DE8956522602FF7CF6E320DC6</td>\n",
       "      <td>000C512BA971962CB1F84E5513F7BBD0</td>\n",
       "      <td>73FFF462EBF71EA1A9A74CA1A43B4B78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>C3575D50206813BA472D74919AF359B5</td>\n",
       "      <td>000C52A00321AABA0DDF68353296FBA5</td>\n",
       "      <td>0906F3E9D72E5A660AAED943A2CAED6E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>CC50151313A97C0CF37EFB64DBF5D5DB</td>\n",
       "      <td>000C5AAC075C7E1C9E73F5C849CAAA5B</td>\n",
       "      <td>42DA46765321D3DFD293FE928E50C00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>FB5825F786166B738B2F88AC288DC4CF</td>\n",
       "      <td>000C5E7F3AD0A543A02738627FE57E39</td>\n",
       "      <td>C96AF5ADE3BE6226E050191824FD8DC2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>6DCBD4BF2802131B249471401DE8D96A</td>\n",
       "      <td>000C685F83CB5726E2F439A3FFF8823B</td>\n",
       "      <td>13A711B58589B34CF26BC94B1E3187C3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581186e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>CD3B458B8E9D5F14BC6AF1F54E71A35F</td>\n",
       "      <td>000C685F83CB5726E2F439A3FFF8823B</td>\n",
       "      <td>B38D85C13B9486563A6E8C94B1781CCD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>F1226DECDBE48845FDD9E3FA31535539</td>\n",
       "      <td>000C694D2C534820EAAF076D2A1024D4</td>\n",
       "      <td>050B4FB4BF95FA0C5A0EFF3A88D99874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>3D67A42B7500F9F6F4438268032DA30E</td>\n",
       "      <td>000C6A0F3867DF2464AE896D8C601749</td>\n",
       "      <td>A124F2247A7E9AD5C45B491674B82AFB</td>\n",
       "      <td>1.580975e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.580975e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>4C16A6C877D4D49066816048BD8AAD96</td>\n",
       "      <td>000C6B7060CBB40B4FBCB844F93BCFC2</td>\n",
       "      <td>2460272B89989866812AB8D12C61EBA1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>7645EA65D727A2807F183ED9317FECBD</td>\n",
       "      <td>000C71858A926549993E6F1FFD99D030</td>\n",
       "      <td>00C61CB36F866F3184653B73AA5BC7FB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581132e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581132e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>EC80BCEAAABDFA763FBA570EBD35546C</td>\n",
       "      <td>000C7BA435F153DC6CBF14412BBA64B4</td>\n",
       "      <td>EC72417D1FA94E0BCF16D3419CA0B17B</td>\n",
       "      <td>1.580973e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>8D5D7454326DC1F55247E93C45E0FE68</td>\n",
       "      <td>000C8659DFEAAF08FD0E67D5F0D5BA29</td>\n",
       "      <td>541D3A45F6F5849A4553E1EDC514CDB8</td>\n",
       "      <td>1.581473e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581473e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>A825C4485E595AE853BF100BD34CDBD2</td>\n",
       "      <td>000C8659DFEAAF08FD0E67D5F0D5BA29</td>\n",
       "      <td>BAD6E27825D5E0E91885E6AE6CECA730</td>\n",
       "      <td>1.581346e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581346e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>AE292DC05C6D5C72601F9F856F943C4A</td>\n",
       "      <td>000C8ECD3C95D632DAC73DAF9EB91C50</td>\n",
       "      <td>9D9A1B3900637F6DC555533C3E1B2DC6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.580991e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>CF2E0F81F376F9CC0B42897A7BF96B9C</td>\n",
       "      <td>000C8F8CDB6A355B1F03EC9B094D71F8</td>\n",
       "      <td>5CE5FE4BE086FC2D913C4D16B22B49B9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             tweet_id                  engaging_user_id  \\\n",
       "0    E7D6C5094767223F6F8789A87A1937AB  00000776B07587ECA9717BFC301F2D6E   \n",
       "1    129F4A868712BA2B98D31AF98C3066E4  00000B85AAF7DE172876FD96718C4469   \n",
       "2    04C6C2175852CDBBC23B2446C7E7C22D  00000E0C9B364891CDE89ECFC54771DE   \n",
       "3    168157826315514C120494D4DF8E6216  00000F04EEDBCF3E1FB9A1948BF353B6   \n",
       "4    B3E3673782A69D9D8A45D3B222F0B073  000010088197DA00D659853E06935B3E   \n",
       "5    AB21A06B694D637075F1EA4F89A05197  000012A6D58B300B1B4098C86223F76E   \n",
       "6    166C053A658691172A7A3CB20D8FB614  000012D4971A83624EF9C6711AE5167D   \n",
       "7    C6016D70FDDAF88BB64B00600B48F788  000013E6563760E3916215D42BE0D406   \n",
       "8    293740496A195D5B20DBE00C3AEFFF17  00001607209C5774DF9207A2AC0EED5F   \n",
       "9    3D89E8BE2E330DA8DD754D58EA07E824  0000170273D2530A0DF580401CC32AE0   \n",
       "10   311EDE393CEBB5E880F5B3A96A69AA94  00001F56CDCF81D2EF635B3C0EDE57EB   \n",
       "11   B9C4540F4798A61C1F17CEB3AE369735  00002086C1D5C05ADE95E1C60FAF71FD   \n",
       "12   EC2126D5DB025A6C66BC24A5596EC475  00002086C1D5C05ADE95E1C60FAF71FD   \n",
       "13   10932CB9E641857BACF9A49D267A8E98  000024E52825D248DDAB9884DC0BD758   \n",
       "14   86E049967C94CF82BA9EB17A2EE4F3CE  000025CDC48B25D9888C6640DE433FE9   \n",
       "15   222EF495AA79DCCC3F32AB9754E9F173  000026C296F4693A6196F90ABAF80FB6   \n",
       "16   9CF609C0D9D099F7C09B52976F5029F7  0000288C66B7563CB98736F96894D9DC   \n",
       "17   6601197539548AAD5C9CB9FCD162A5C7  00002C99ACC8931540C190542549BFE0   \n",
       "18   B72C9FD782AF79BA56755410E3C617FC  000030DA986805A0B204966360B8AABB   \n",
       "19   C33F498C0F3FE07667B08B834A2FF474  00003B622698D49D3868B01E557FE4E6   \n",
       "20   35359883026EF6D9A31F6C962517A15D  000043D9A730DF47697D0750F509B56A   \n",
       "21   C95D525FFA8A789ABBA005B9F7BE7174  000043D9A730DF47697D0750F509B56A   \n",
       "22   3C21DCFB8E3FEC1CB3D2BFB413A78220  000046C8606F1C3F5A7296222C88084B   \n",
       "23   C83B3441704D4E6172B86CEF3F66845C  00004DF6D6CAB6361EDF8FDE86365ECE   \n",
       "24   42E7832DAB2B068F63B32B6AD85B3F9D  0000510EC3AFC6F9FB8E411852A84877   \n",
       "25   C281F4EF6011EFC61BDE3E96216C0A6A  0000510EC3AFC6F9FB8E411852A84877   \n",
       "26   C7FB1313DB6D1013282343FFA2AF41FD  0000581864A04C34E289F984EBD20562   \n",
       "27   28D9CAE78D1F3E9877A9559757D57293  00005B5734CD2CB88CBD541ADEBA0F4F   \n",
       "28   558CAF543304741E670682E4F6CDA1CC  00005B5734CD2CB88CBD541ADEBA0F4F   \n",
       "29   D2F0691D4B7D3933824640F6AED9D308  00005BD9676C7C12A80E686070A180BD   \n",
       "..                                ...                               ...   \n",
       "970  2DF672498994C4F3217A3E536D5B3DEB  000C325ED4406815ED6D0A01F4A022DE   \n",
       "971  B0FAE386FC61AFACE3558DB8F25915AC  000C327DF907A4C7E8657067AF2E956E   \n",
       "972  1F75C1A9ED7009EB5E19791C3109E3AF  000C342ECA70A84E597B8F96C0CC255A   \n",
       "973  9E5221F9ADF15DC8D7E41E5B1144A5D3  000C342ECA70A84E597B8F96C0CC255A   \n",
       "974  5E51F328A948CAAFE94D1AC18529A022  000C3830AD0EDE399D0053FB415F81BE   \n",
       "975  C283BA903523D54A5BBA8B32595A50B4  000C3EF37A9E9E4F389BE839A806B506   \n",
       "976  7A7229B71FCBA2E78DA395B5F43EE2C5  000C40888D533376F6C7CEC626C48496   \n",
       "977  844C05347C6E3D9B413E6C4D846FDF88  000C40888D533376F6C7CEC626C48496   \n",
       "978  90649352FDF0B954B99D228D1B2F87BC  000C40888D533376F6C7CEC626C48496   \n",
       "979  9BB764177047DEFB11A8BEA281E31A27  000C47CADA1342AE252E9CA346DA1EC6   \n",
       "980  DA5B79AC4D0C4007D953E5122F818CA4  000C48903A26C8EDAE2FDC770D83F194   \n",
       "981  16F93A7AB2618E7EDB1F2A17826EB41C  000C49C5EF6A8C7E9BFA13D19474ED32   \n",
       "982  FB84B4A226894A7022A2FB4052DBFE43  000C49C5EF6A8C7E9BFA13D19474ED32   \n",
       "983  4304C651D4A573409A724B112B2D65BE  000C4DAD25C18E2B1E1644F7C4BD9210   \n",
       "984  100A5AC9ED4FD3833B6BBFC0B0A4F6EB  000C4F1D0B27F9D985774F6F4976F3E7   \n",
       "985  37D5378DE8956522602FF7CF6E320DC6  000C512BA971962CB1F84E5513F7BBD0   \n",
       "986  C3575D50206813BA472D74919AF359B5  000C52A00321AABA0DDF68353296FBA5   \n",
       "987  CC50151313A97C0CF37EFB64DBF5D5DB  000C5AAC075C7E1C9E73F5C849CAAA5B   \n",
       "988  FB5825F786166B738B2F88AC288DC4CF  000C5E7F3AD0A543A02738627FE57E39   \n",
       "989  6DCBD4BF2802131B249471401DE8D96A  000C685F83CB5726E2F439A3FFF8823B   \n",
       "990  CD3B458B8E9D5F14BC6AF1F54E71A35F  000C685F83CB5726E2F439A3FFF8823B   \n",
       "991  F1226DECDBE48845FDD9E3FA31535539  000C694D2C534820EAAF076D2A1024D4   \n",
       "992  3D67A42B7500F9F6F4438268032DA30E  000C6A0F3867DF2464AE896D8C601749   \n",
       "993  4C16A6C877D4D49066816048BD8AAD96  000C6B7060CBB40B4FBCB844F93BCFC2   \n",
       "994  7645EA65D727A2807F183ED9317FECBD  000C71858A926549993E6F1FFD99D030   \n",
       "995  EC80BCEAAABDFA763FBA570EBD35546C  000C7BA435F153DC6CBF14412BBA64B4   \n",
       "996  8D5D7454326DC1F55247E93C45E0FE68  000C8659DFEAAF08FD0E67D5F0D5BA29   \n",
       "997  A825C4485E595AE853BF100BD34CDBD2  000C8659DFEAAF08FD0E67D5F0D5BA29   \n",
       "998  AE292DC05C6D5C72601F9F856F943C4A  000C8ECD3C95D632DAC73DAF9EB91C50   \n",
       "999  CF2E0F81F376F9CC0B42897A7BF96B9C  000C8F8CDB6A355B1F03EC9B094D71F8   \n",
       "\n",
       "                 engaged_with_user_id  retweet_timestamp  reply_timestamp  \\\n",
       "0    D557B03872EF8986F7F4426AE094B2FE                NaN              NaN   \n",
       "1    424822AC982CE0E8965506C63B44EC12       1.581498e+09              NaN   \n",
       "2    1EC14E26417AA926095530AC591BA9CE                NaN              NaN   \n",
       "3    9B9595B6FEB8948BDDF0D222F27E0118                NaN              NaN   \n",
       "4    525DC99B7CB8F1AC4AD3E66C53FA38E0                NaN              NaN   \n",
       "5    7E1E2FAD93219D0247BDBE451AB343E9       1.581347e+09              NaN   \n",
       "6    A0FD6DF4B4FBF62949708CDB97CC8124                NaN     1.581009e+09   \n",
       "7    629A622B84E4C67FAB56DCF0DBD785AA                NaN              NaN   \n",
       "8    AD86A376FA5F26E67263D5FCA8A5BD59                NaN              NaN   \n",
       "9    2F236A7D11ECDAF1FC472E9ACC32AE6B                NaN              NaN   \n",
       "10   85A39142470D65A77BB9E86B054AD321                NaN              NaN   \n",
       "11   0C89F01A8644F9B685BF2225F00EF34B                NaN              NaN   \n",
       "12   46097861C196B25F2C56606CD32AE14C                NaN              NaN   \n",
       "13   618642C3684BC6B65F905C289D1F376F                NaN              NaN   \n",
       "14   49D04A274A357E3039E1DF0F78E2975F                NaN              NaN   \n",
       "15   162984295C1BCFF55D7977B9ADA50AD8                NaN              NaN   \n",
       "16   A702303ED1A25C6DD1393BC0CCABF94A       1.581018e+09              NaN   \n",
       "17   0FACF6DB63422FC388A2BB4AA1585AB2                NaN              NaN   \n",
       "18   0D01AD1116E22830152CC5FC78CE952D                NaN              NaN   \n",
       "19   5B8C4D92F1AE859A2FD69BB405B03347                NaN              NaN   \n",
       "20   418D921524B4A26261D5F24586CCEDD7                NaN              NaN   \n",
       "21   9586F04FF09A614BAE30367575053EC4                NaN              NaN   \n",
       "22   D1AA2C85FA644D64346EDD88470525F2                NaN              NaN   \n",
       "23   5611A5DB21B6C40C8E3848A4DECFBB24                NaN              NaN   \n",
       "24   24F43670B7EF0441CCF800C6B77403BC                NaN              NaN   \n",
       "25   1216DCF3AF02393B3139C17C28DDDE02                NaN              NaN   \n",
       "26   E4B09E5CE7BC5D9FB753CDFCF63ACCC0                NaN              NaN   \n",
       "27   5A6DCA175E07A222854B7F115C50A3B8       1.580956e+09              NaN   \n",
       "28   8397BF026AF4CD632EBB10441B55A22F                NaN              NaN   \n",
       "29   758F32F4069006B21E15EA41BC9EBCEA       1.581220e+09              NaN   \n",
       "..                                ...                ...              ...   \n",
       "970  C11B1575C2D534C0E848F07645392B79                NaN              NaN   \n",
       "971  0E8ADEAB18E9E77C25732091412CF4E7                NaN              NaN   \n",
       "972  33347DECF6D85A55B6F3466FCBF33C3E                NaN              NaN   \n",
       "973  C1CC7182933A775CCE50459B5ECBA354                NaN              NaN   \n",
       "974  ED0BEE31DC4C4D5BB9204FB738F5235F                NaN              NaN   \n",
       "975  5DFE3006923CC533F49745879C1AA0AD       1.581028e+09              NaN   \n",
       "976  4A39C95294F157A005618CEC35CFEDBB                NaN              NaN   \n",
       "977  31EC136527B50D20155FE3745043554D                NaN     1.581140e+09   \n",
       "978  9DADDD754358BC15F6CCC7FA44000DA9                NaN              NaN   \n",
       "979  4CCF7B73021DC0212539A569B83199E7                NaN              NaN   \n",
       "980  566A6275D7315EAE052ABB177CDFCA60                NaN              NaN   \n",
       "981  35B5BC9DAE87F4F5AD9C4636F8718E27                NaN              NaN   \n",
       "982  75CD9CE5D7F26B532F31CDA3027E3509                NaN              NaN   \n",
       "983  88E9D79DF89B1118C6C52B8791842318                NaN              NaN   \n",
       "984  71BBC322E6D40D590715CA8814C72E0A                NaN              NaN   \n",
       "985  73FFF462EBF71EA1A9A74CA1A43B4B78                NaN              NaN   \n",
       "986  0906F3E9D72E5A660AAED943A2CAED6E                NaN              NaN   \n",
       "987  42DA46765321D3DFD293FE928E50C00A                NaN              NaN   \n",
       "988  C96AF5ADE3BE6226E050191824FD8DC2                NaN              NaN   \n",
       "989  13A711B58589B34CF26BC94B1E3187C3                NaN              NaN   \n",
       "990  B38D85C13B9486563A6E8C94B1781CCD                NaN              NaN   \n",
       "991  050B4FB4BF95FA0C5A0EFF3A88D99874                NaN              NaN   \n",
       "992  A124F2247A7E9AD5C45B491674B82AFB       1.580975e+09              NaN   \n",
       "993  2460272B89989866812AB8D12C61EBA1                NaN              NaN   \n",
       "994  00C61CB36F866F3184653B73AA5BC7FB                NaN     1.581132e+09   \n",
       "995  EC72417D1FA94E0BCF16D3419CA0B17B       1.580973e+09              NaN   \n",
       "996  541D3A45F6F5849A4553E1EDC514CDB8       1.581473e+09              NaN   \n",
       "997  BAD6E27825D5E0E91885E6AE6CECA730       1.581346e+09              NaN   \n",
       "998  9D9A1B3900637F6DC555533C3E1B2DC6                NaN     1.580991e+09   \n",
       "999  5CE5FE4BE086FC2D913C4D16B22B49B9                NaN              NaN   \n",
       "\n",
       "     retweet_with_comment_timestamp  like_timestamp  \n",
       "0                               NaN             NaN  \n",
       "1                               NaN    1.581498e+09  \n",
       "2                               NaN    1.581061e+09  \n",
       "3                               NaN    1.581329e+09  \n",
       "4                               NaN    1.580958e+09  \n",
       "5                               NaN    1.581347e+09  \n",
       "6                               NaN             NaN  \n",
       "7                               NaN             NaN  \n",
       "8                               NaN    1.581009e+09  \n",
       "9                               NaN             NaN  \n",
       "10                              NaN    1.581190e+09  \n",
       "11                              NaN             NaN  \n",
       "12                              NaN    1.581045e+09  \n",
       "13                              NaN    1.581375e+09  \n",
       "14                              NaN    1.581064e+09  \n",
       "15                              NaN             NaN  \n",
       "16                              NaN    1.581018e+09  \n",
       "17                              NaN             NaN  \n",
       "18                              NaN             NaN  \n",
       "19                              NaN    1.581260e+09  \n",
       "20                              NaN    1.581369e+09  \n",
       "21                              NaN    1.580963e+09  \n",
       "22                              NaN             NaN  \n",
       "23                              NaN             NaN  \n",
       "24                              NaN             NaN  \n",
       "25                              NaN    1.581191e+09  \n",
       "26                              NaN    1.581548e+09  \n",
       "27                              NaN    1.580956e+09  \n",
       "28                              NaN             NaN  \n",
       "29                              NaN             NaN  \n",
       "..                              ...             ...  \n",
       "970                             NaN             NaN  \n",
       "971                             NaN             NaN  \n",
       "972                             NaN    1.581520e+09  \n",
       "973                             NaN             NaN  \n",
       "974                             NaN             NaN  \n",
       "975                             NaN    1.581028e+09  \n",
       "976                             NaN             NaN  \n",
       "977                             NaN             NaN  \n",
       "978                             NaN             NaN  \n",
       "979                             NaN             NaN  \n",
       "980                             NaN    1.581430e+09  \n",
       "981                             NaN             NaN  \n",
       "982                             NaN             NaN  \n",
       "983                             NaN    1.581423e+09  \n",
       "984                             NaN             NaN  \n",
       "985                             NaN             NaN  \n",
       "986                             NaN             NaN  \n",
       "987                             NaN             NaN  \n",
       "988                             NaN             NaN  \n",
       "989                             NaN    1.581186e+09  \n",
       "990                             NaN             NaN  \n",
       "991                             NaN             NaN  \n",
       "992                             NaN    1.580975e+09  \n",
       "993                             NaN             NaN  \n",
       "994                             NaN    1.581132e+09  \n",
       "995                             NaN             NaN  \n",
       "996                             NaN    1.581473e+09  \n",
       "997                             NaN    1.581346e+09  \n",
       "998                             NaN             NaN  \n",
       "999                             NaN             NaN  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc = twitter_preproc(spark, sc, train, column_names, SCHEMA)\n",
    "print(preproc.getDF().show(5))\n",
    "#print(preproc.getDF().show(5))\n",
    "import pandas as pd\n",
    "pd.DataFrame(preproc.getDF().take(1000), columns=preproc.getDF().columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|like_timestamp|\n",
      "+--------------+\n",
      "|          null|\n",
      "|    1581497622|\n",
      "|    1581060554|\n",
      "|    1581328518|\n",
      "|    1580957807|\n",
      "|    1581346588|\n",
      "|          null|\n",
      "|          null|\n",
      "|    1581009248|\n",
      "|          null|\n",
      "|    1581189873|\n",
      "|          null|\n",
      "|    1581045318|\n",
      "|    1581375276|\n",
      "|    1581063697|\n",
      "|          null|\n",
      "|    1581017998|\n",
      "|          null|\n",
      "|          null|\n",
      "|    1581260483|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------+----+\n",
      "|like_timestamp|like|\n",
      "+--------------+----+\n",
      "|          null|   0|\n",
      "|    1581497622|   1|\n",
      "|    1581060554|   1|\n",
      "|    1581328518|   1|\n",
      "|    1580957807|   1|\n",
      "|    1581346588|   1|\n",
      "|          null|   0|\n",
      "|          null|   0|\n",
      "|    1581009248|   1|\n",
      "|          null|   0|\n",
      "|    1581189873|   1|\n",
      "|          null|   0|\n",
      "|    1581045318|   1|\n",
      "|    1581375276|   1|\n",
      "|    1581063697|   1|\n",
      "|          null|   0|\n",
      "|    1581017998|   1|\n",
      "|          null|   0|\n",
      "|          null|   0|\n",
      "|    1581260483|   1|\n",
      "+--------------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "### Tweet-Type OneHotEncodings:\n",
      "+----------+-------------+-----------------+--------------------+----------------+--------------------+--------------------+-----------+---------------+\n",
      "|tweet_type|tweet_type_id|tweet_type_onehot|       present_media|present_media_id|present_media_onehot|            language|language_id|language_onehot|\n",
      "+----------+-------------+-----------------+--------------------+----------------+--------------------+--------------------+-----------+---------------+\n",
      "|  TopLevel|          0.0|    (2,[0],[1.0])|              [none]|             0.0|       (6,[0],[1.0])|22C448FF81263D4BA...|        1.0| (30,[1],[1.0])|\n",
      "|   Retweet|          1.0|    (2,[1],[1.0])|              [none]|             0.0|       (6,[0],[1.0])|22C448FF81263D4BA...|        1.0| (30,[1],[1.0])|\n",
      "|  TopLevel|          0.0|    (2,[0],[1.0])|              [none]|             0.0|       (6,[0],[1.0])|22C448FF81263D4BA...|        1.0| (30,[1],[1.0])|\n",
      "|   Retweet|          1.0|    (2,[1],[1.0])|              [none]|             0.0|       (6,[0],[1.0])|D3164C7FBCF2565DD...|        0.0| (30,[0],[1.0])|\n",
      "|  TopLevel|          0.0|    (2,[0],[1.0])|             [photo]|             1.0|       (6,[1],[1.0])|22C448FF81263D4BA...|        1.0| (30,[1],[1.0])|\n",
      "|  TopLevel|          0.0|    (2,[0],[1.0])|             [video]|             2.0|       (6,[2],[1.0])|167115458A0DBDFF7...|        5.0| (30,[5],[1.0])|\n",
      "|  TopLevel|          0.0|    (2,[0],[1.0])|[photo, photo, ph...|             5.0|       (6,[5],[1.0])|ECED8A16BE2A5E887...|        3.0| (30,[3],[1.0])|\n",
      "|     Quote|          2.0|        (2,[],[])|              [none]|             0.0|       (6,[0],[1.0])|ECED8A16BE2A5E887...|        3.0| (30,[3],[1.0])|\n",
      "|   Retweet|          1.0|    (2,[1],[1.0])|             [video]|             2.0|       (6,[2],[1.0])|D3164C7FBCF2565DD...|        0.0| (30,[0],[1.0])|\n",
      "|  TopLevel|          0.0|    (2,[0],[1.0])|             [video]|             2.0|       (6,[2],[1.0])|D3164C7FBCF2565DD...|        0.0| (30,[0],[1.0])|\n",
      "|  TopLevel|          0.0|    (2,[0],[1.0])|             [photo]|             1.0|       (6,[1],[1.0])|4DC22C3F31C5C4372...|        6.0| (30,[6],[1.0])|\n",
      "|  TopLevel|          0.0|    (2,[0],[1.0])|      [photo, photo]|             3.0|       (6,[3],[1.0])|D3164C7FBCF2565DD...|        0.0| (30,[0],[1.0])|\n",
      "|     Quote|          2.0|        (2,[],[])|              [none]|             0.0|       (6,[0],[1.0])|D3164C7FBCF2565DD...|        0.0| (30,[0],[1.0])|\n",
      "|  TopLevel|          0.0|    (2,[0],[1.0])|              [none]|             0.0|       (6,[0],[1.0])|D3164C7FBCF2565DD...|        0.0| (30,[0],[1.0])|\n",
      "|  TopLevel|          0.0|    (2,[0],[1.0])|[photo, photo, ph...|             5.0|       (6,[5],[1.0])|22C448FF81263D4BA...|        1.0| (30,[1],[1.0])|\n",
      "|     Quote|          2.0|        (2,[],[])|              [none]|             0.0|       (6,[0],[1.0])|ECED8A16BE2A5E887...|        3.0| (30,[3],[1.0])|\n",
      "|  TopLevel|          0.0|    (2,[0],[1.0])|              [none]|             0.0|       (6,[0],[1.0])|D3164C7FBCF2565DD...|        0.0| (30,[0],[1.0])|\n",
      "|  TopLevel|          0.0|    (2,[0],[1.0])|      [photo, photo]|             3.0|       (6,[3],[1.0])|D3164C7FBCF2565DD...|        0.0| (30,[0],[1.0])|\n",
      "|   Retweet|          1.0|    (2,[1],[1.0])|             [video]|             2.0|       (6,[2],[1.0])|06D61DCBBE938971E...|        2.0| (30,[2],[1.0])|\n",
      "|   Retweet|          1.0|    (2,[1],[1.0])|             [video]|             2.0|       (6,[2],[1.0])|06D61DCBBE938971E...|        2.0| (30,[2],[1.0])|\n",
      "+----------+-------------+-----------------+--------------------+----------------+--------------------+--------------------+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import * \n",
    "\n",
    "data = preproc.getDF()\n",
    "data.select(\"like_timestamp\").show()\n",
    "foo = data.withColumn(\"like\", when(data[\"like_timestamp\"].isNull(), 0).otherwise(1))\n",
    "foo.select(\"like_timestamp\", \"like\").show()\n",
    "#data = data.drop(\"text_tokens\").withColumnRenamed(\"vector\", \"text_tokens\")\n",
    "print(\"### Tweet-Type OneHotEncodings:\")\n",
    "explainonehot = preproc.explainOneHot()\n",
    "explainonehot.show()\n",
    "#data.show()\n",
    "#data.groupBy(\"engaging_user_is_verified\").count().show()\n",
    "#data = data.select(\"engaging_user_is_verified\", \"engaged_with_user_is_verified\", \"engaged_follows_engaging\")\\\n",
    "#    .replace([\"false\",\"true\"], [\"0\",\"1\"])..show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|present_media|\n",
      "+-------------+\n",
      "|       [none]|\n",
      "|       [none]|\n",
      "|       [none]|\n",
      "|       [none]|\n",
      "|      [photo]|\n",
      "+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[hashtags: string, tweet_type: string, language: string, tweet_timestamp: bigint, engaged_with_user_follower_count: bigint, engaged_with_user_following_count: bigint, engaged_with_user_is_verified: boolean, engaged_with_user_account_creation: bigint, engaging_user_id: string, engaging_user_follower_count: bigint, engaging_user_following_count: bigint, engaging_user_is_verified: boolean, engaging_user_account_creation: bigint, engaged_follows_engaging: boolean, reply_timestamp: bigint, retweet_timestamp: bigint, retweet_with_comment_timestamp: bigint, like_timestamp: bigint, text_tokens: array<string>, present_media: string, tweet_type_id: double, present_media_id: double, tweet_type_onehot: vector, present_media_onehot: vector, present_media2: string]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select(\"present_media\").show(5)\n",
    "data.withColumn(\"present_media2\", data[\"present_media\"].cast(StringType()))\n",
    "#data.select(\"present_media\").rdd.map(lambda x: str(x[0])).toDF(schema= StructType([\n",
    "#                StructField(\"present_media\", StringType())])).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PythonRDD[63] at RDD at PythonRDD.scala:53'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.foreach(print)\n",
    "str(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+-------------+-------------+\n",
      "|categoryIndex1|categoryIndex2| categoryVec1| categoryVec2|\n",
      "+--------------+--------------+-------------+-------------+\n",
      "|           0.0|           1.0|(2,[0],[1.0])|(2,[1],[1.0])|\n",
      "|           1.0|           0.0|(2,[1],[1.0])|(2,[0],[1.0])|\n",
      "|           2.0|           1.0|    (2,[],[])|(2,[1],[1.0])|\n",
      "|           0.0|           2.0|(2,[0],[1.0])|    (2,[],[])|\n",
      "|           0.0|           1.0|(2,[0],[1.0])|(2,[1],[1.0])|\n",
      "|           2.0|           0.0|    (2,[],[])|(2,[0],[1.0])|\n",
      "+--------------+--------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (0.0, 1.0),\n",
    "    (1.0, 0.0),\n",
    "    (2.0, 1.0),\n",
    "    (0.0, 2.0),\n",
    "    (0.0, 1.0),\n",
    "    (2.0, 0.0)\n",
    "], [\"categoryIndex1\", \"categoryIndex2\"])\n",
    "\n",
    "encoder = OneHotEncoderEstimator(inputCols=[\"categoryIndex1\", \"categoryIndex2\"],\n",
    "                                 outputCols=[\"categoryVec1\", \"categoryVec2\"])\n",
    "model = encoder.fit(df)\n",
    "encoded = model.transform(df)\n",
    "encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer\n",
    "\n",
    "data = preproc.getDF()\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text_tokens\",outputCol=\"vector\", pattern=\"\\t\")\n",
    "tokenized = regexTokenizer.transform(data)\n",
    "\n",
    "tokenized.select(\"vector\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting demo.py\n"
     ]
    }
   ],
   "source": [
    "%%file demo.py\n",
    "\n",
    "\n",
    "from twitter_preproc import twitter_preproc\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "#spark = SparkSession.builder.appName(\"ChiSquareSpark\").getOrCreate()\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Pipeline\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "\n",
    "# sample file with 1000 tweets for checking the pipeline\n",
    "train = \"///user/e11920598/traintweet_1000.tsv\"\n",
    "\n",
    "preproc = twitter_preproc(spark, sc, train)\n",
    "print(preproc.getDF().show(5))\n",
    "\n",
    "\n",
    "sc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark) overrides detected (/opt/cloudera/parcels/CDH/lib/spark).\n",
      "WARNING: Running spark-class from user-defined location.\n",
      "20/06/06 16:26:47 INFO spark.SparkContext: Running Spark version 2.4.0-cdh6.3.2\n",
      "20/06/06 16:26:47 INFO logging.DriverLogger: Added a local log appender at: /tmp/spark-95acd95f-2bb4-4950-bc77-662ca74baeab/__driver_logs__/driver.log\n",
      "20/06/06 16:26:47 INFO spark.SparkContext: Submitted application: Pipeline\n",
      "20/06/06 16:26:47 INFO spark.SecurityManager: Changing view acls to: e11920598\n",
      "20/06/06 16:26:47 INFO spark.SecurityManager: Changing modify acls to: e11920598\n",
      "20/06/06 16:26:47 INFO spark.SecurityManager: Changing view acls groups to: \n",
      "20/06/06 16:26:47 INFO spark.SecurityManager: Changing modify acls groups to: \n",
      "20/06/06 16:26:47 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(e11920598); groups with view permissions: Set(); users  with modify permissions: Set(e11920598); groups with modify permissions: Set()\n",
      "20/06/06 16:26:47 INFO util.Utils: Successfully started service 'sparkDriver' on port 40223.\n",
      "20/06/06 16:26:47 INFO spark.SparkEnv: Registering MapOutputTracker\n",
      "20/06/06 16:26:47 INFO spark.SparkEnv: Registering BlockManagerMaster\n",
      "20/06/06 16:26:47 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "20/06/06 16:26:47 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "20/06/06 16:26:47 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-b5e841a6-5826-4e85-9c72-4c4474dab04a\n",
      "20/06/06 16:26:47 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB\n",
      "20/06/06 16:26:47 INFO spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "20/06/06 16:26:47 INFO util.log: Logging initialized @2856ms\n",
      "20/06/06 16:26:47 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: 2018-09-04T23:11:46+02:00, git hash: 3ce520221d0240229c862b122d2b06c12a625732\n",
      "20/06/06 16:26:47 INFO server.Server: Started @2968ms\n",
      "20/06/06 16:26:47 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "20/06/06 16:26:47 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "20/06/06 16:26:47 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "20/06/06 16:26:47 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "20/06/06 16:26:47 WARN util.Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "20/06/06 16:26:47 WARN util.Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "20/06/06 16:26:47 WARN util.Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
      "20/06/06 16:26:47 WARN util.Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n",
      "20/06/06 16:26:47 WARN util.Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n",
      "20/06/06 16:26:47 WARN util.Utils: Service 'SparkUI' could not bind on port 4049. Attempting port 4050.\n",
      "20/06/06 16:26:47 INFO server.AbstractConnector: Started ServerConnector@6b588ecd{HTTP/1.1,[http/1.1]}{0.0.0.0:4050}\n",
      "20/06/06 16:26:47 INFO util.Utils: Successfully started service 'SparkUI' on port 4050.\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5aad2a0b{/jobs,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1b56f2cf{/jobs/json,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4b231bc7{/jobs/job,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7dbdd439{/jobs/job/json,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@51d191cb{/stages,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@27f5515{/stages/json,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@62fad302{/stages/stage,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54d87832{/stages/stage/json,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@608ed368{/stages/pool,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3f5fde0e{/stages/pool/json,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2904f346{/storage,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3e8a07bc{/storage/json,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@28899696{/storage/rdd,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69678227{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@67f7c28e{/environment,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9ae8e2b{/environment/json,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d7794ae{/executors,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@38d4459d{/executors/json,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@616e13bb{/executors/threadDump,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1ccc166b{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4d4f23b8{/static,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@787dc45e{/,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2beb43cd{/api,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a626254{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c395428{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:26:47 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://c100.local:4050\n",
      "20/06/06 16:26:48 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:26:48 INFO util.Utils: Using initial executors = 4, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances\n",
      "20/06/06 16:26:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "20/06/06 16:26:48 INFO client.RMProxy: Connecting to ResourceManager at c100.local/10.7.0.100:8032\n",
      "20/06/06 16:26:49 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:26:49 INFO yarn.Client: Requesting a new application from cluster with 18 NodeManagers\n",
      "20/06/06 16:26:49 INFO conf.Configuration: resource-types.xml not found\n",
      "20/06/06 16:26:49 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "20/06/06 16:26:49 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (143360 MB per container)\n",
      "20/06/06 16:26:49 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\n",
      "20/06/06 16:26:49 INFO yarn.Client: Setting up container launch context for our AM\n",
      "20/06/06 16:26:49 INFO yarn.Client: Setting up the launch environment for our AM container\n",
      "20/06/06 16:26:49 INFO yarn.Client: Preparing resources for our AM container\n",
      "20/06/06 16:26:50 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:26:51 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:26:51 INFO yarn.Client: Uploading resource file:/tmp/spark-95acd95f-2bb4-4950-bc77-662ca74baeab/__spark_conf__4692943125962393701.zip -> hdfs://nameservice1/user/e11920598/.sparkStaging/application_1591257126602_0273/__spark_conf__.zip\n",
      "20/06/06 16:26:52 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:26:53 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:26:54 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:26:55 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:26:56 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:26:57 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:26:58 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:26:59 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:00 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:00 INFO spark.SecurityManager: Changing view acls to: e11920598\n",
      "20/06/06 16:27:00 INFO spark.SecurityManager: Changing modify acls to: e11920598\n",
      "20/06/06 16:27:00 INFO spark.SecurityManager: Changing view acls groups to: \n",
      "20/06/06 16:27:00 INFO spark.SecurityManager: Changing modify acls groups to: \n",
      "20/06/06 16:27:00 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(e11920598); groups with view permissions: Set(); users  with modify permissions: Set(e11920598); groups with modify permissions: Set()\n",
      "20/06/06 16:27:00 INFO yarn.Client: Submitting application application_1591257126602_0273 to ResourceManager\n",
      "20/06/06 16:27:00 INFO impl.YarnClientImpl: Submitted application application_1591257126602_0273\n",
      "20/06/06 16:27:01 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:01 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:01 INFO yarn.Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: [Sat Jun 06 16:27:01 +0200 2020] Application is added to the scheduler and is not yet activated.  (Resource request: <memory:1024, vCores:1> exceeds the available resources of the node and the request cannot be reserved)\n",
      "\t ApplicationMaster host: N/A\n",
      "\t ApplicationMaster RPC port: -1\n",
      "\t queue: root.adbs20.e11920598\n",
      "\t start time: 1591453620331\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: http://c100.local:8088/proxy/application_1591257126602_0273/\n",
      "\t user: e11920598\n",
      "20/06/06 16:27:02 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:02 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:03 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:03 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:04 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:04 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:05 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:05 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:06 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:06 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:07 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:07 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:08 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:08 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:09 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:09 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:10 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:10 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:11 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:11 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:12 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:12 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:13 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:13 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:14 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:14 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:15 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:15 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:16 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:16 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:17 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:17 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:18 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:18 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:19 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:19 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:20 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:20 INFO yarn.Client: Application report for application_1591257126602_0273 (state: ACCEPTED)\n",
      "20/06/06 16:27:21 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:21 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> c100.local, PROXY_URI_BASES -> http://c100.local:8088/proxy/application_1591257126602_0273), /proxy/application_1591257126602_0273\n",
      "20/06/06 16:27:21 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.\n",
      "20/06/06 16:27:21 INFO yarn.Client: Application report for application_1591257126602_0273 (state: RUNNING)\n",
      "20/06/06 16:27:21 INFO yarn.Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: N/A\n",
      "\t ApplicationMaster host: 10.7.0.105\n",
      "\t ApplicationMaster RPC port: -1\n",
      "\t queue: root.adbs20.e11920598\n",
      "\t start time: 1591453620331\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: http://c100.local:8088/proxy/application_1591257126602_0273/\n",
      "\t user: e11920598\n",
      "20/06/06 16:27:21 INFO cluster.YarnClientSchedulerBackend: Application application_1591257126602_0273 has started running.\n",
      "20/06/06 16:27:21 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1591257126602_0273 and attemptId None\n",
      "20/06/06 16:27:21 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34996.\n",
      "20/06/06 16:27:21 INFO netty.NettyBlockTransferService: Server created on c100.local:34996\n",
      "20/06/06 16:27:21 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "20/06/06 16:27:21 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c100.local, 34996, None)\n",
      "20/06/06 16:27:21 INFO storage.BlockManagerMasterEndpoint: Registering block manager c100.local:34996 with 366.3 MB RAM, BlockManagerId(driver, c100.local, 34996, None)\n",
      "20/06/06 16:27:21 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c100.local, 34996, None)\n",
      "20/06/06 16:27:21 INFO storage.BlockManager: external shuffle service port = 7337\n",
      "20/06/06 16:27:21 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, c100.local, 34996, None)\n",
      "20/06/06 16:27:21 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.\n",
      "20/06/06 16:27:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7456a65c{/metrics/json,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:27:22 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:22 INFO scheduler.EventLoggingListener: Logging events to hdfs://nameservice1/user/spark/spark2ApplicationHistory/application_1591257126602_0273\n",
      "20/06/06 16:27:22 INFO util.Utils: Using initial executors = 4, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances\n",
      "20/06/06 16:27:22 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!\n",
      "20/06/06 16:27:22 INFO spark.SparkContext: Registered listener com.cloudera.spark.lineage.NavigatorAppListener\n",
      "20/06/06 16:27:22 INFO logging.DriverLogger$DfsAsyncWriter: Started driver log file sync to: /user/spark/driverLogs/application_1591257126602_0273_driver.log\n",
      "20/06/06 16:27:22 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)\n",
      "20/06/06 16:27:22 INFO internal.SharedState: loading hive config file: file:/etc/hive/conf.cloudera.hive/hive-site.xml\n",
      "20/06/06 16:27:22 INFO internal.SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir ('/user/hive/warehouse').\n",
      "20/06/06 16:27:22 INFO internal.SharedState: Warehouse path is '/user/hive/warehouse'.\n",
      "20/06/06 16:27:22 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL.\n",
      "20/06/06 16:27:22 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3c778e6b{/SQL,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:27:22 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/json.\n",
      "20/06/06 16:27:22 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2162b2dc{/SQL/json,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:27:22 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution.\n",
      "20/06/06 16:27:22 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1bfd4ed1{/SQL/execution,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:27:22 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution/json.\n",
      "20/06/06 16:27:22 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@16bb0f17{/SQL/execution/json,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:27:22 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /static/sql.\n",
      "20/06/06 16:27:22 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@16041e64{/static/sql,null,AVAILABLE,@Spark}\n",
      "20/06/06 16:27:22 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\n",
      "20/06/06 16:27:23 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:23 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint\n",
      "20/06/06 16:27:23 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 300.5 KB, free 366.0 MB)\n",
      "20/06/06 16:27:23 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 30.5 KB, free 366.0 MB)\n",
      "20/06/06 16:27:23 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on c100.local:34996 (size: 30.5 KB, free: 366.3 MB)\n",
      "20/06/06 16:27:23 INFO spark.SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0\n",
      "20/06/06 16:27:24 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:24 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "20/06/06 16:27:24 INFO spark.SparkContext: Starting job: runJob at PythonRDD.scala:153\n",
      "20/06/06 16:27:24 INFO scheduler.DAGScheduler: Got job 0 (runJob at PythonRDD.scala:153) with 1 output partitions\n",
      "20/06/06 16:27:24 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (runJob at PythonRDD.scala:153)\n",
      "20/06/06 16:27:24 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "20/06/06 16:27:24 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "20/06/06 16:27:24 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "20/06/06 16:27:24 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 366.0 MB)\n",
      "20/06/06 16:27:24 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 366.0 MB)\n",
      "20/06/06 16:27:24 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on c100.local:34996 (size: 4.4 KB, free: 366.3 MB)\n",
      "20/06/06 16:27:24 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1164\n",
      "20/06/06 16:27:24 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (PythonRDD[2] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "20/06/06 16:27:24 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks\n",
      "20/06/06 16:27:25 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:25 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:26 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:27 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:28 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:29 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:30 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:31 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:32 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:33 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:34 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:35 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:36 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:37 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:38 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:39 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:40 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:40 WARN cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "20/06/06 16:27:41 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:42 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:43 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:44 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:45 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:46 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:47 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:48 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:49 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:50 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:51 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:52 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:53 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:54 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:55 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:55 WARN cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "20/06/06 16:27:56 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:57 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:58 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:27:59 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:00 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:01 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:02 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:03 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:04 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:05 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:06 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:07 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:08 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:09 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:10 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:10 WARN cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "20/06/06 16:28:11 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:12 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:13 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:14 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:15 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:16 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:17 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:18 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:19 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:20 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:21 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:22 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:23 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:24 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:25 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:25 WARN cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "20/06/06 16:28:26 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:27 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:28 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:29 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:30 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:31 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:32 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:33 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:34 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:35 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:36 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:37 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:38 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:39 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:40 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:40 WARN cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "20/06/06 16:28:41 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:42 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:43 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:44 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:45 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:46 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:47 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:48 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:49 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:50 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:51 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:52 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:53 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:54 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:55 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:55 WARN cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "20/06/06 16:28:56 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:57 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:58 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:28:59 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:00 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:01 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:02 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:03 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:04 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:05 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:06 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:07 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:08 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:09 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:10 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:10 WARN cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "20/06/06 16:29:11 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:12 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:13 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:14 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:15 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:16 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:17 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:18 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:19 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:20 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:21 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:22 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:23 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:24 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:25 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:25 WARN cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "20/06/06 16:29:26 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:27 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:28 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:29 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:30 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:31 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:32 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:33 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:34 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:35 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:36 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:37 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:38 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:39 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:40 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:40 WARN cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "20/06/06 16:29:41 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:42 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all\n",
      "20/06/06 16:29:42 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.7.0.104:46450) with ID 1\n",
      "20/06/06 16:29:42 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1)\n",
      "20/06/06 16:29:42 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, c104.local, executor 1, partition 0, NODE_LOCAL, 7925 bytes)\n",
      "20/06/06 16:29:42 INFO storage.BlockManagerMasterEndpoint: Registering block manager c104.local:35596 with 4.1 GB RAM, BlockManagerId(1, c104.local, 35596, None)\n",
      "20/06/06 16:29:43 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on c104.local:35596 (size: 4.4 KB, free: 4.1 GB)\n",
      "20/06/06 16:29:43 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on c104.local:35596 (size: 30.5 KB, free: 4.1 GB)\n",
      "20/06/06 16:29:45 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3257 ms on c104.local (executor 1) (1/1)\n",
      "20/06/06 16:29:45 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "20/06/06 16:29:45 INFO python.PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 57753\n",
      "20/06/06 16:29:45 INFO scheduler.DAGScheduler: ResultStage 0 (runJob at PythonRDD.scala:153) finished in 140.979 s\n",
      "20/06/06 16:29:45 INFO scheduler.DAGScheduler: Job 0 finished: runJob at PythonRDD.scala:153, took 141.059762 s\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adbs20/e11920598/git/twitter/demo.py\", line 18, in <module>\n",
      "    preproc = twitter_preproc(spark, sc, train)\n",
      "  File \"/home/adbs20/e11920598/git/twitter/twitter_preproc.py\", line 12, in __init__\n",
      "    self.inputData = inputRDD.toDF()    \n",
      "  File \"/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 58, in toDF\n",
      "  File \"/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 757, in createDataFrame\n",
      "  File \"/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 401, in _createFromRDD\n",
      "  File \"/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 381, in _inferSchema\n",
      "  File \"/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1062, in _infer_schema\n",
      "TypeError: Can not infer schema for type: <class 'str'>\n",
      "20/06/06 16:29:45 INFO spark.SparkContext: Invoking stop() from shutdown hook\n",
      "20/06/06 16:29:46 INFO server.AbstractConnector: Stopped Spark@6b588ecd{HTTP/1.1,[http/1.1]}{0.0.0.0:4050}\n",
      "20/06/06 16:29:46 INFO ui.SparkUI: Stopped Spark web UI at http://c100.local:4050\n",
      "20/06/06 16:29:46 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\n",
      "20/06/06 16:29:46 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\n",
      "20/06/06 16:29:46 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\n",
      "20/06/06 16:29:46 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices\n",
      "(serviceOption=None,\n",
      " services=List(),\n",
      " started=false)\n",
      "20/06/06 16:29:46 INFO cluster.YarnClientSchedulerBackend: Stopped\n",
      "20/06/06 16:29:50 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "20/06/06 16:29:50 INFO memory.MemoryStore: MemoryStore cleared\n",
      "20/06/06 16:29:50 INFO storage.BlockManager: BlockManager stopped\n",
      "20/06/06 16:29:50 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\n",
      "20/06/06 16:29:50 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "20/06/06 16:29:50 INFO spark.SparkContext: Successfully stopped SparkContext\n",
      "20/06/06 16:29:50 INFO util.ShutdownHookManager: Shutdown hook called\n",
      "20/06/06 16:29:50 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-7dd63ea1-eb33-499d-b26d-5c373fb56172\n",
      "20/06/06 16:29:50 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-95acd95f-2bb4-4950-bc77-662ca74baeab\n",
      "20/06/06 16:29:50 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-95acd95f-2bb4-4950-bc77-662ca74baeab/pyspark-d6754d16-25f7-4661-bee2-34926c8e0074\n"
     ]
    }
   ],
   "source": [
    "### rather use it on the command line than here\n",
    "#! spark-submit --num-executors=4 --total-executor-cores 16 --executor-memory=8G demo.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "python",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
