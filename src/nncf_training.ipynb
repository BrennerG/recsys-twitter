{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack\n",
    "import twitter_preproc\n",
    "import importlib\n",
    "importlib.reload(twitter_preproc)\n",
    "from twitter_preproc import *\n",
    "from operator import attrgetter\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from twitter_preproc import twitter_preproc\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys, traceback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Spark Context\n",
    "# conf = SparkConf().setAll([('spark.executor.memory', '32g'), ('spark.executor.instances','8'),('spark.executor.cores', '12'), ('spark.driver.memory','64g'), ('spark.driver.memoryOverhead', '64g')])\n",
    "conf = SparkConf()\n",
    "spark = SparkSession.builder.appName(\"nncf\").config(conf=conf).getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "# Small datasets\n",
    "# train = \"///tmp/traintweet_1000.tsv\"\n",
    "train = \"///tmp/traintweet_10k.tsv\"\n",
    "# test = \"///user/e11920598/test_1000.tsv\"\n",
    "\n",
    "# Full datasets\n",
    "# the full train file has 121.386.431 lines\n",
    "# the full test file has 12.434.838 lines\n",
    "# train = \"///user/pknees/RSC20/training.tsv\"\n",
    "# test= \"///user/pknees/RSC20/test.tsv\"\n",
    "\n",
    "preproc = twitter_preproc(spark, sc, train, MF=True)\n",
    "traindata = preproc.getDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN PREPROCESSING (INDEXING, ONE-HOTTING, MATRIX CONVERSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%file NNPreprocessor.py\n",
    "import pyspark.sql.functions as Fun\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack\n",
    "import twitter_preproc\n",
    "import importlib\n",
    "importlib.reload(twitter_preproc)\n",
    "from twitter_preproc import *\n",
    "from operator import attrgetter\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from twitter_preproc import twitter_preproc\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "import torch\n",
    "import sys, traceback\n",
    "\n",
    "class NNPreprocessor:\n",
    "\n",
    "    def get_id_indices(self,df, id_column):\n",
    "        id_indices = df.select(id_column).orderBy(id_column).rdd.zipWithIndex().toDF()\n",
    "        id_indices = id_indices.withColumn(id_column, Fun.col(\"_1\")[id_column])\\\n",
    "            .select(Fun.col(id_column), Fun.col(\"_2\").alias(id_column + \"_index\"))\n",
    "        return id_indices\n",
    "\n",
    "    # map function to convert from spark vectors to sparse numpy csr matrix\n",
    "    def as_matrix(self,vec):\n",
    "        data, indices = vec.values, vec.indices\n",
    "        shape = 1, vec.size\n",
    "        return csr_matrix((data, indices, np.array([0, vec.values.size])), shape)\n",
    "\n",
    "    # calls as_matrix\n",
    "    def get_pytorch_sparse(self,attr, traindata_ohe):\n",
    "        features = traindata_ohe.rdd.map(attrgetter(attr))\n",
    "        mats = features.map(self.as_matrix)\n",
    "        mat = mats.reduce(lambda x, y: vstack([x, y]))\n",
    "        return mat\n",
    "\n",
    "    # convert to pytorch format\n",
    "    def transform_to_sparse_tensor(self,data):\n",
    "        coo = data.tocoo()\n",
    "        values = coo.data\n",
    "        indices = np.vstack((coo.row, coo.col))\n",
    "        i = torch.LongTensor(indices)\n",
    "        v = torch.FloatTensor(values)\n",
    "        shape = coo.shape\n",
    "        return torch.sparse.FloatTensor(i, v, torch.Size(shape))\n",
    "\n",
    "    def nn_preprocess(self,data):\n",
    "        traindata = data\n",
    "\n",
    "        # INDEXING & ONE-HOT ENCODING\n",
    "        # get indexed columns\n",
    "        tweet_id_idx = self.get_id_indices(df=traindata, id_column=\"tweet_id\")\n",
    "        user_id_idx = self.get_id_indices(df=traindata, id_column=\"engaging_user_id\")\n",
    "        # rejoin the columns\n",
    "        indexed_data = traindata.join(tweet_id_idx, ['tweet_id']).join(user_id_idx, ['engaging_user_id'])\n",
    "\n",
    "        # one-hot-encode\n",
    "        pipeline = Pipeline(stages=[\n",
    "            OneHotEncoder(inputCol=\"tweet_id_index\",  outputCol=\"tweet_id_ohe\"),\n",
    "            OneHotEncoder(inputCol=\"engaging_user_id_index\",  outputCol=\"user_id_ohe\")\n",
    "        ])\n",
    "        model = pipeline.fit(indexed_data.select(['tweet_id_index', 'engaging_user_id_index', 'like']))\n",
    "        traindata_ohe = model.transform(indexed_data)\n",
    "\n",
    "        # select and parse to pandas dataframe\n",
    "        df = pd.DataFrame(traindata_ohe.select(['tweet_id_ohe', 'user_id_ohe', 'like']).collect(), columns=['tweet_id_ohe', 'user_id_ohe', 'like'])\n",
    "\n",
    "        # create tweets and users vector in correct format    \n",
    "        tweet_sparse = self.get_pytorch_sparse(\"tweet_id_ohe\", traindata_ohe)\n",
    "        user_sparse = self.get_pytorch_sparse(\"user_id_ohe\", traindata_ohe)\n",
    "        tweets = self.transform_to_sparse_tensor(tweet_sparse).to_dense()\n",
    "        users = self.transform_to_sparse_tensor(user_sparse).to_dense()\n",
    "        \n",
    "        # create target variables in correct format\n",
    "        y = torch.FloatTensor(traindata_ohe.select(\"like\").collect()) \n",
    "        target = y  \n",
    "        target = target.view(1, -1).t()\n",
    "\n",
    "        return tweets, users, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnp = NNPreprocessor()\n",
    "tweets, users, target = nnp.nn_preprocess(traindata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%file NNCFNet.py\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define Neural Network\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, users:int, items:int, k:int):\n",
    "        super(Net, self).__init__()\n",
    "        self.dense1 = nn.Linear(users, k)\n",
    "        self.dense2 = nn.Linear(items, k)\n",
    "        self.fc1 = nn.Linear(2*k, k)\n",
    "        self.fc2 = nn.Linear(k, math.floor(k/2))\n",
    "        self.fc3 = nn.Linear(math.floor(k/2), 1)\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        users = F.relu(self.dense1(users))\n",
    "        items = F.relu(self.dense2(items))\n",
    "        # concat users and items into 1 vector\n",
    "        x = torch.cat((users, items), dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        sigfried = nn.Sigmoid()\n",
    "        x = sigfried(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start Training\n",
      "epoch  1\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6898, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6917, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6983, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6884, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6869, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6987, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6997, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6884, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6921, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6912, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6888, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6983, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6983, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7007, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7011, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6874, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6916, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7002, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6917, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7002, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "epoch  2\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6898, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6912, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6921, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6955, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6917, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6898, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6955, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6917, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7020, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6893, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6898, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6898, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6921, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6917, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6884, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6869, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7011, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6997, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6983, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6888, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6983, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6960, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "epoch  3\n",
      "tensor(0.6888, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6870, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6879, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6874, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6917, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6987, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7030, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6983, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7016, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6902, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6870, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6912, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6893, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6912, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6997, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6888, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6987, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6921, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6997, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6983, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "epoch  4\n",
      "tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7025, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6983, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6987, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6888, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6860, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6917, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7011, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6917, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6921, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6983, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6893, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6879, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6893, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6865, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6865, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7015, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6893, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7020, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7006, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6874, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7001, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6902, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6921, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7001, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6982, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6884, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6912, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6975, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "epoch  5\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6949, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6917, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6912, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6987, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7006, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6949, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6917, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6921, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6879, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6893, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6996, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6912, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6921, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6921, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6987, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6912, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6982, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6898, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6912, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6875, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6921, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6946, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "from NNCFNet import Net\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Initalize Hyperparameters\n",
    "k = 32\n",
    "n_epochs = 5\n",
    "batch_size = 256\n",
    "\n",
    "# Initialize Neural Network\n",
    "net = Net(users.shape[1], tweets.shape[1], k)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001)\n",
    "criterion = nn.BCELoss()\n",
    "output = net(users, tweets)\n",
    "\n",
    "# Start training\n",
    "print(\"\\nStart Training\")\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"epoch \", epoch+1)\n",
    "\n",
    "    try:\n",
    "    # X is a torch Variable\n",
    "        permutation = torch.randperm(users.size()[0])\n",
    "\n",
    "        for i in range(0,users.size()[0], batch_size):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch_x_user = users[indices]\n",
    "            batch_x_tweet = tweets[indices]\n",
    "            batch_y = target[indices]\n",
    "\n",
    "            outputs = net.forward(batch_x_user, batch_x_tweet)\n",
    "            loss = criterion(outputs,batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(loss)\n",
    "\n",
    "    except:\n",
    "        traceback.print_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "PATH = '../misc/NNCF_model_save.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "print(\"\\n\\nDONE. model saved to \", PATH, \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
