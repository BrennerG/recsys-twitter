{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'NNCFNet' from '/home/adbs20/e1447920/recsys-twitter/src/NNCFNet.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack\n",
    "import twitter_preproc\n",
    "import importlib\n",
    "importlib.reload(twitter_preproc)\n",
    "from twitter_preproc import *\n",
    "from operator import attrgetter\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from twitter_preproc import twitter_preproc\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "\n",
    "import sys, traceback\n",
    "\n",
    "import NNPreprocessor as NNP\n",
    "importlib.reload(NNP)\n",
    "import NNCFNet\n",
    "importlib.reload(NNCFNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Spark Context\n",
    "# conf = SparkConf().setAll([('spark.executor.memory', '32g'), ('spark.executor.instances','8'),('spark.executor.cores', '12'), ('spark.driver.memory','64g'), ('spark.driver.memoryOverhead', '64g')])\n",
    "conf = SparkConf()\n",
    "spark = SparkSession.builder.appName(\"nncf_eval\").config(conf=conf).getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.8 ms, sys: 6.98 ms, total: 18.7 ms\n",
      "Wall time: 2.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train = \"///tmp/traintweet_1000.tsv\" # irrelevant; only needed for preproc class to shut up\n",
    "#test = \"///user/e11920598/test_1000.tsv\" # no access!\n",
    "test = \"///tmp/traintweet_1000.tsv\" # nat actually train set\n",
    "#test= \"///user/pknees/RSC20/test.tsv\"\n",
    "\n",
    "preproc = twitter_preproc(spark, sc, train, testFile=test, MF=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 2 µs, total: 9 µs\n",
      "Wall time: 12.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_df = preproc.getTestDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nnpre = NNP.NNPreprocessor()\n",
    "users, tweets, target = nnpre.nn_preprocess(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_PATH = '../misc/NNCF_model_save.pth'\n",
    "users_dim = 9999\n",
    "tweets_dim = 9999\n",
    "k = 32\n",
    "\n",
    "model = NNCFNet.Net(users_dim, tweets_dim, k)\n",
    "model.load_state_dict(torch.load(model_PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "padding_users = users_dim - users.shape[1] - 1\n",
    "padding_tweets = tweets_dim - tweets.shape[1] - 1\n",
    "padded_users = F.pad(users, (padding,1))\n",
    "padded_tweets = F.pad(tweets, (padding,1))\n",
    "\n",
    "# run\n",
    "outputs = model(padded_users, padded_tweets)\n",
    "\n",
    "# label classes\n",
    "probabilities = outputs.detach().numpy().flatten()\n",
    "predicted = probabilities > probabilities.mean()\n",
    "truth = target.detach().numpy().flatten().astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(truth, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
