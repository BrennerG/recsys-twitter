{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import ensemble\n",
    "import importlib\n",
    "importlib.reload(ensemble)\n",
    "from ensemble import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.config(\"spark.executor.memoryOverhead\", \"64g\")\\\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"ensemble\")\\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"60s\")\\\n",
    "    .config(\"spark.executor.memory\", \"32g\")\\\n",
    "    .config(\"spark.driver.memory\", \"32g\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"64g\")\\\n",
    "    .config(\"spark.sql.crossJoin.enabled\", True)\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/tmp/supersecret_ensemble/\"\n",
    "\n",
    "train_pred_files = {\n",
    "    \"like\": {\n",
    "        \"mf\": base_dir + \"mf/train_prediction_like.tsv\", \n",
    "        \"rf\": base_dir + \"rf/rf_like_out_ensembletrain_format.csv\", \n",
    "        \"nncf\": base_dir + \"nncf/like.supersecret_ensembletrain5k_bootstrap.tsv\"\n",
    "    },\n",
    "    \"reply\": {\n",
    "        \"mf\": base_dir + \"mf/train_prediction_reply.tsv\", \n",
    "        \"rf\": base_dir + \"rf/rf_reply_out_ensembletrain_format.csv\", \n",
    "        \"nncf\": base_dir + \"nncf/reply.supersecret_ensembletrain5k_bootstrap.tsv\"\n",
    "    },\n",
    "    \"retweet\": {\n",
    "        \"mf\": base_dir + \"mf/train_prediction_retweet.tsv\", \n",
    "        \"rf\": base_dir + \"rf/rf_retweet_out_ensembletrain_format.csv\", \n",
    "        \"nncf\": base_dir + \"nncf/retweet.supersecret_ensembletrain5k_bootstrap.tsv\"\n",
    "    },\n",
    "    \"retweet_with_comment\": {\n",
    "        \"mf\": base_dir + \"mf/train_prediction_retweet_with_comment.tsv\", \n",
    "        \"rf\": base_dir + \"rf/rf_retweet_comment_out_ensembletrain_format.csv\", \n",
    "        \"nncf\": base_dir + \"nncf/retweet_comment.supersecret_ensembletrain5k_bootstrap.tsv\"\n",
    "    },\n",
    "}\n",
    "\n",
    "test_pred_files = {\n",
    "    \"like\": {\n",
    "        \"mf\": base_dir + \"mf/test_prediction_like.tsv\", \n",
    "        \"rf\": base_dir + \"rf/rf_like_out_test_format.csv\", \n",
    "        \"nncf\": base_dir + \"nncf/like.supersecret_test5k_bootstrap.tsv\"\n",
    "    },\n",
    "    \"reply\": {\n",
    "        \"mf\": base_dir + \"mf/test_prediction_reply.tsv\", \n",
    "        \"rf\": base_dir + \"rf/rf_reply_out_test_format.csv\", \n",
    "        \"nncf\": base_dir + \"nncf/reply.supersecret_test5k_bootstrap.tsv\"\n",
    "    },\n",
    "    \"retweet\": {\n",
    "        \"mf\": base_dir + \"mf/test_prediction_retweet.tsv\", \n",
    "        \"rf\": base_dir + \"rf/rf_retweet_out_test_format.csv\", \n",
    "        \"nncf\": base_dir + \"nncf/retweet.supersecret_test5k_bootstrap.tsv\"\n",
    "    },\n",
    "    \"retweet_with_comment\": {\n",
    "        \"mf\": base_dir + \"mf/test_prediction_retweet_with_comment.tsv\", \n",
    "        \"rf\": base_dir + \"rf/rf_retweet_comment_out_test_format.csv\", \n",
    "        \"nncf\": base_dir + \"nncf/retweet_comment.supersecret_test5k_bootstrap.tsv\"\n",
    "    },\n",
    "}\n",
    "    \n",
    "train_label_file = base_dir + \"labels/train_labels.tsv\"\n",
    "test_label_file = base_dir + \"labels/test_labels.tsv\"\n",
    "schemas = {\n",
    "    \"nncf\": StructType([\n",
    "    StructField(\"engaging_user_id\", StringType()),\n",
    "    StructField(\"tweet_id\", StringType()),\n",
    "    StructField(\"prediction\", DoubleType())\n",
    "    ]),\n",
    "    \"rf\": StructType([\n",
    "        StructField(\"tweet_id\", StringType()),\n",
    "        StructField(\"engaging_user_id\", StringType()),\n",
    "        StructField(\"prediction\", DoubleType())\n",
    "    ])\n",
    "}\n",
    "\n",
    "ens = ensemble(spark, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_exist(path):\n",
    "    fs = sc._jvm.org.apache.hadoop.fs.FileSystem.get(sc._jsc.hadoopConfiguration())\n",
    "    return fs.exists(sc._jvm.org.apache.hadoop.fs.Path(path))\n",
    "for engagement in train_pred_files:\n",
    "    for model_name in train_pred_files[engagement]:\n",
    "        if not file_exist(train_pred_files[engagement][model_name]):\n",
    "            print(\"File does not exist for engagement {} and model_name {}\".format(engagement, model_name))\n",
    "        if not file_exist(test_pred_files[engagement][model_name]):\n",
    "            print(\"File does not exist for engagement {} and model_name {}\".format(engagement, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- engaging_user_id: string (nullable = true)\n",
      " |-- like: string (nullable = true)\n",
      " |-- reply: string (nullable = true)\n",
      " |-- retweet: string (nullable = true)\n",
      " |-- retweet_with_comment: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- engaging_user_id: string (nullable = true)\n",
      " |-- like: string (nullable = true)\n",
      " |-- reply: string (nullable = true)\n",
      " |-- retweet: string (nullable = true)\n",
      " |-- retweet_with_comment: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- engaging_user_id: string (nullable = true)\n",
      " |-- like: string (nullable = true)\n",
      " |-- reply: string (nullable = true)\n",
      " |-- retweet: string (nullable = true)\n",
      " |-- retweet_with_comment: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- engaging_user_id: string (nullable = true)\n",
      " |-- like: string (nullable = true)\n",
      " |-- reply: string (nullable = true)\n",
      " |-- retweet: string (nullable = true)\n",
      " |-- retweet_with_comment: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- engaging_user_id: string (nullable = true)\n",
      " |-- like: string (nullable = true)\n",
      " |-- reply: string (nullable = true)\n",
      " |-- retweet: string (nullable = true)\n",
      " |-- retweet_with_comment: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- engaging_user_id: string (nullable = true)\n",
      " |-- like: string (nullable = true)\n",
      " |-- reply: string (nullable = true)\n",
      " |-- retweet: string (nullable = true)\n",
      " |-- retweet_with_comment: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- engaging_user_id: string (nullable = true)\n",
      " |-- like: string (nullable = true)\n",
      " |-- reply: string (nullable = true)\n",
      " |-- retweet: string (nullable = true)\n",
      " |-- retweet_with_comment: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- engaging_user_id: string (nullable = true)\n",
      " |-- like: string (nullable = true)\n",
      " |-- reply: string (nullable = true)\n",
      " |-- retweet: string (nullable = true)\n",
      " |-- retweet_with_comment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coef_list = []\n",
    "for engagement in train_pred_files:\n",
    "    lr_model = ens.train(train_pred_files[engagement], schemas, train_label_file, engagement)\n",
    "    lr_model.save(base_dir + \"model_\" + engagement)\n",
    "    coef_list.append(lr_model.coefficients)\n",
    "\n",
    "    eval_df = ens.test_evaluate(lr_model, test_pred_files[engagement], schemas, test_label_file, engagement, thresholds=[0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "    eval_df.to_csv(\"ensemble_{}.csv\".format(engagement), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.647919876905869, 1.3963699553481372, 0.0697410798905738]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(coef_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list = [[e] + list(coef) for (coef, e) in zip(coef_list, train_pred_files.keys())]\n",
    "pd.DataFrame(coef_list, columns=[\"engagement\", \"mf\", \"rf\", \"nncf\"]).to_csv(\"coefficients.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "python",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
