{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from IPython.display import display\n",
    "\n",
    "import matrix_factorization\n",
    "import importlib\n",
    "importlib.reload(matrix_factorization)\n",
    "from matrix_factorization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.config(\"spark.executor.memoryOverhead\", \"64g\")\\\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"matrix-factorization\")\\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"60s\")\\\n",
    "    .config(\"spark.executor.memory\", \"32g\")\\\n",
    "    .config(\"spark.driver.memory\", \"32g\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"64g\")\\\n",
    "    .config(\"spark.sql.crossJoin.enabled\", True)\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = matrix_factorization(spark, sc)\n",
    "mf.read_train(\"///user/pknees/RSC20/training.tsv\", is_preprocessed=False)\n",
    "mf.read_val(\"///user/pknees/RSC20/val.tsv\", is_preprocessed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = model.recommendForAllItems(10)\n",
    "\n",
    "# Generate top 10 movie recommendations for a specified set of users\n",
    "users = df.select(als.getUserCol()).distinct().limit(3)\n",
    "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "# Generate top 10 user recommendations for a specified set of movies\n",
    "movies = df.select(als.getItemCol()).distinct().limit(3)\n",
    "movieSubSetRecs = model.recommendForItemSubset(movies, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "python",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
