{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack\n",
    "import twitter_preproc\n",
    "import importlib\n",
    "importlib.reload(twitter_preproc)\n",
    "from twitter_preproc import *\n",
    "from operator import attrgetter\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from twitter_preproc import twitter_preproc\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "\n",
    "import sys, traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Spark Context\n",
    "conf = SparkConf().setAll([('spark.executor.memory', '32g'), ('spark.executor.instances','8'),('spark.executor.cores', '12'), ('spark.driver.memory','64g'), ('spark.driver.memoryOverhead', '64g')])\n",
    "#conf = SparkConf()\n",
    "spark = SparkSession.builder.appName(\"nncf\").config(conf=conf).getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small datasets\n",
    "# train = \"///tmp/traintweet_1000.tsv\"\n",
    "# train = \"///tmp/traintweet_10k.tsv\"\n",
    "# test = \"///user/e11920598/test_1000.tsv\"\n",
    "\n",
    "# Full datasets\n",
    "# the full train file has 121.386.431 lines\n",
    "# the full test file has 12.434.838 lines\n",
    "train = \"///user/pknees/RSC20/training.tsv\"\n",
    "# test= \"///user/pknees/RSC20/test.tsv\"\n",
    "\n",
    "preproc = twitter_preproc(spark, sc, train)\n",
    "traindata = preproc.getDF()\n",
    "\n",
    "\n",
    "\n",
    "# TODO using the twitter_prepoc method for matrix factorization might be more efficient!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDEXING & ONE HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as Fun\n",
    "\n",
    "# used for StringIndexing\n",
    "# returns 2 columns: [original_id, indexed_id]\n",
    "def get_id_indices(df, id_column):\n",
    "        id_indices = df.select(id_column).orderBy(id_column).rdd.zipWithIndex().toDF()\n",
    "        id_indices = id_indices.withColumn(id_column, Fun.col(\"_1\")[id_column])\\\n",
    "                .select(Fun.col(id_column), Fun.col(\"_2\").alias(id_column + \"_index\"))\n",
    "        return id_indices\n",
    "\n",
    "# get indexed columns\n",
    "tweet_id_idx = get_id_indices(df=traindata, id_column=\"tweet_id\")\n",
    "user_id_idx = get_id_indices(df=traindata, id_column=\"engaging_user_id\")\n",
    "# rejoin the columns\n",
    "indexed_data = traindata.join(tweet_id_idx, ['tweet_id']).join(user_id_idx, ['engaging_user_id'])\n",
    "\n",
    "# one-hot-encode\n",
    "pipeline = Pipeline(stages=[\n",
    "    OneHotEncoder(inputCol=\"tweet_id_index\",  outputCol=\"tweet_id_ohe\"),\n",
    "    OneHotEncoder(inputCol=\"engaging_user_id_index\",  outputCol=\"user_id_ohe\")\n",
    "])\n",
    "model = pipeline.fit(indexed_data.select(['tweet_id_index', 'engaging_user_id_index', 'like']))\n",
    "traindata_ohe = model.transform(indexed_data)\n",
    "\n",
    "# select and parse to pandas dataframe\n",
    "df = pd.DataFrame(traindata_ohe.select(['tweet_id_ohe', 'user_id_ohe', 'like']).collect(), columns=['tweet_id_ohe', 'user_id_ohe', 'like'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATRIX & VECTOR CONVERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map function to convert from spark vectors to sparse numpy csr matrix\n",
    "def as_matrix(vec):\n",
    "    data, indices = vec.values, vec.indices\n",
    "    shape = 1, vec.size\n",
    "    return csr_matrix((data, indices, np.array([0, vec.values.size])), shape)\n",
    "\n",
    "# calls as_matrix\n",
    "def get_pytorch_sparse(attr):\n",
    "    features = traindata_ohe.rdd.map(attrgetter(attr))\n",
    "    mats = features.map(as_matrix)\n",
    "    mat = mats.reduce(lambda x, y: vstack([x, y]))\n",
    "    return mat\n",
    "\n",
    "# convert to pytorch format\n",
    "def transform_to_sparse_tensor(data):\n",
    "    coo = data.tocoo()\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    shape = coo.shape\n",
    "\n",
    "    return torch.sparse.FloatTensor(i, v, torch.Size(shape))\n",
    "\n",
    "# convert matrices to pytorch tensor format\n",
    "tweet_sparse = get_pytorch_sparse(\"tweet_id_ohe\")\n",
    "user_sparse = get_pytorch_sparse(\"user_id_ohe\")\n",
    "tweet_sparse = transform_to_sparse_tensor(tweet_sparse).to_dense()\n",
    "user_sparse = transform_to_sparse_tensor(user_sparse).to_dense()\n",
    "\n",
    "# create target variables in correct format\n",
    "y = torch.FloatTensor(traindata_ohe.select(\"like\").collect()) \n",
    "target = y  \n",
    "target = target.view(1, -1).t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Net(\n",
      "  (dense1): Linear(in_features=9999, out_features=32, bias=True)\n",
      "  (dense2): Linear(in_features=9999, out_features=32, bias=True)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define Neural Network\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, users, items, k):\n",
    "        super(Net, self).__init__()\n",
    "        self.dense1 = nn.Linear(users.shape[1], k)\n",
    "        self.dense2 = nn.Linear(items.shape[1], k)\n",
    "        self.fc1 = nn.Linear(2*k, k)\n",
    "        self.fc2 = nn.Linear(k, math.floor(k/2))\n",
    "        self.fc3 = nn.Linear(math.floor(k/2), 1)\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        users = F.relu(self.dense1(users))\n",
    "        items = F.relu(self.dense2(items))\n",
    "        # concat users and items into 1 vector\n",
    "        x = torch.cat((users, items), dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        sigfried = nn.Sigmoid()\n",
    "        x = sigfried(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initalize Hyperparameters\n",
    "k = 32\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001)\n",
    "n_epochs = 1\n",
    "batch_size = 1024\n",
    "\n",
    "# Initialize Neural Network\n",
    "net = Net(user_sparse, tweet_sparse, k)\n",
    "output = net(user_sparse, tweet_sparse)\n",
    "print('\\n\\n',net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start Training\n",
      "epoch  1\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6816, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6838, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7120, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6860, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6795, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7229, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6838, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7056, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7164, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7121, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7055, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6686, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6838, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6838, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6904, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6860, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7164, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7164, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7033, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7186, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7229, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7055, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7186, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7056, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7121, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6881, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6664, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7120, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6991, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6904, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6991, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7251, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7143, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6838, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6838, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6904, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7049, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "epoch  2\n",
      "tensor(0.7207, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6991, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6838, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6773, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6838, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7295, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7056, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7164, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6708, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7207, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7056, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6730, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7056, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6904, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6904, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6860, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7164, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6794, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7121, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7164, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7055, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7143, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6817, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7120, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6773, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6904, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6904, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7164, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6817, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6817, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7056, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6860, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7229, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6860, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7186, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6860, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7164, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6925, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7164, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6773, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7186, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7164, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7120, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7208, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6885, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStart Training\")\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"epoch \", epoch+1)\n",
    "\n",
    "    try:\n",
    "    # X is a torch Variable\n",
    "        permutation = torch.randperm(user_sparse.size()[0])\n",
    "\n",
    "        for i in range(0,user_sparse.size()[0], batch_size):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch_x_user = user_sparse[indices]\n",
    "            batch_x_tweet = tweet_sparse[indices]\n",
    "            batch_y = target[indices]\n",
    "\n",
    "            outputs = net.forward(batch_x_user, batch_x_tweet)\n",
    "            loss = criterion(outputs,batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(loss)\n",
    "\n",
    "    except:\n",
    "        traceback.print_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "PATH = './NNCF_model_save.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "print(\"\\n\\nDONE. model saved to \", PATH, \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
