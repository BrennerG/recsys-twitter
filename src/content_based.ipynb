{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classifier on a single label using text_tokens as content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import twitter_preproc\n",
    "\n",
    "conf = SparkConf().setAll([\n",
    "    (\"num-executors\", 4), \n",
    "    (\"total-executor-cores\", 16), \n",
    "    (\"executor-memory\", \"8g\"),\n",
    "    (\"spark.yarn.executor.memoryOverhead\", \"64g\")])\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"///tmp/traintweet_1000.tsv\"\n",
    "ENGAGEMENTS = [\"like\", \"reply\", \"retweet\", \"retweet_with_comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "\n",
    "importlib.reload(twitter_preproc)\n",
    "preproc = twitter_preproc.twitter_preproc(spark, sc, datapath, MF=True)\n",
    "df = preproc.getDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "for engagement in ENGAGEMENTS:\n",
    "            df = df.withColumn(engagement, when(df[engagement + \"_timestamp\"].isNotNull(), 1).cast(ByteType()))\\\n",
    "                .drop(engagement + \"_timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0, subset=ENGAGEMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\"text_tokens\",\"tweet_id\",\"engaging_user_id\",\"like\",\"reply\",\"retweet\",\"retweet_with_comment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle BERT tokens like words, maybe TODO: find deeper meaning in the tokens(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer,NGram,CountVectorizer,IDF,StringIndexer,Normalizer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"engaging_user_id\", outputCol=\"engaging_user_id_idx\")\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text_tokens\", outputCol=\"terms\", pattern=\"\\t\")\n",
    "cv = CountVectorizer(inputCol=\"terms\", outputCol=\"vector\")\n",
    "idf = IDF(inputCol=\"vector\", outputCol=\"features\")\n",
    "normalizer=Normalizer(inputCol=\"features\",outputCol=\"normed_features\")\n",
    "pipeline = Pipeline(stages=[stringIndexer,regexTokenizer, cv,idf,normalizer])\n",
    "\n",
    "model = pipeline.fit(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text_tokens: string (nullable = true)\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- engaging_user_id: string (nullable = true)\n",
      " |-- like: byte (nullable = true)\n",
      " |-- reply: byte (nullable = true)\n",
      " |-- retweet: byte (nullable = true)\n",
      " |-- retweet_with_comment: byte (nullable = true)\n",
      " |-- engaging_user_id_idx: double (nullable = false)\n",
      " |-- terms: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- vector: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- normed_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevance Feedback with Rocchios method \n",
    "7, S.36\n",
    "\n",
    "for now with a single user and selected tweeet yeet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sps\n",
    "\n",
    "# Returns the positive/negative feedback from a \n",
    "def build_user_profile(df,user_id):  \n",
    "    user_vectors = df.where(df[\"engaging_user_id_idx\"] == user_id)\n",
    "    \n",
    "    pos = user_vectors.where(user_vectors[\"like\"] == 1)\n",
    "    neg = user_vectors.where(user_vectors[\"like\"] == 0)\n",
    "    \n",
    "    pos_rdd = pos[[\"engaging_user_id_idx\",\"normed_features\"]].rdd\n",
    "    neg_rdd = neg[[\"engaging_user_id_idx\",\"normed_features\"]].rdd\n",
    "    \n",
    "    pos_count = pos_rdd.count()\n",
    "    neg_count = neg_rdd.count()\n",
    "    \n",
    "    positive_weight = 1\n",
    "    negative_weight = 1\n",
    "   \n",
    "    if(pos_count > 0  & neg_count > 0):\n",
    "        pos_agg = pos_rdd.map(lambda row: (row.engaging_user_id_idx,sps.csc_matrix(row.normed_features))).reduceByKey(lambda k,v:k+v)\n",
    "        neg_agg = neg_rdd.map(lambda row: (row.engaging_user_id_idx,sps.csc_matrix(row.normed_features))).reduceByKey(lambda k,v:k+v)\n",
    "        user_profile = positive_weight * (1/pos_count * pos_agg.collect()[0][1]) - negative_weight * (1 / neg_count) * neg_agg.collect()[0][1] \n",
    "    elif(pos_count > 0  & neg_count == 0):\n",
    "        pos_agg = pos_rdd.map(lambda row: (row.engaging_user_id_idx,sps.csc_matrix(row.normed_features))).reduceByKey(lambda k,v:k+v)\n",
    "        user_profile = positive_weight * (1/pos_count * pos_agg.collect()[0][1])\n",
    "      \n",
    "    return user_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = build_user_profile(data,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = data.select(\"tweet_id\",\"normed_features\").rdd\n",
    "tweet_features = tweets.map(lambda row: (row.tweet_id,sps.csc_matrix(row.normed_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "t = tweet_features.map(lambda t: (t[0],cosine(t[1].toarray(),u.toarray())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('E7D6C5094767223F6F8789A87A1937AB', 1.0),\n",
       " ('129F4A868712BA2B98D31AF98C3066E4', 0.9931761850625865),\n",
       " ('04C6C2175852CDBBC23B2446C7E7C22D', 0.9840771707836296),\n",
       " ('168157826315514C120494D4DF8E6216', 0.9871904330427985),\n",
       " ('B3E3673782A69D9D8A45D3B222F0B073', 0.9899149407959815)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(df,tweet_id,user_id):\n",
    "    u = build_user_profile(df,user_id)\n",
    "    \n",
    "    t = df.where(df[\"tweet_id\"] == tweet_id)\n",
    "    t = t.select(\"normed_features\")\n",
    "    t = sps.csc_matrix(t.first()[0])\n",
    "    \n",
    "    return cosine(u.toarray(),t.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9871904330427985"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(data,\"168157826315514C120494D4DF8E6216\",1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Convert cosine distance to probability somehow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Based approach\n",
    "\n",
    "Our approach was to treat the BERT tokens like words and generate an id-idf feature vector. Every tweet is represented as a sparse feature vector, the user profile is generated with every tweet which the user has engaged with. \n",
    "\n",
    "We tried to use Rocchio's Method to generate relevance feedback for a user. This method was not feasable, due to the massive amount of features. For Rocchio's Method past rated items are split into two classes, positive feedback and negative feedback. To compute the user profile, one has to aggregate each feature vector from the positive and negative ones. This step was crucial for performance, because the aggreation of a sparse vector with ~32.000 features did not finish in a reasonable time.\n",
    "\n",
    "## Vector aggregation in pyspark\n",
    "\n",
    "It is neccessary in pyspark to transform a SparseVector into an intermediate format, in this case an array, to perform aggregate functions. So for the linear combination of our user feedback, we had to aggregate arrays instead of SparseVectors, which is also a factor for the poor performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "python",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
