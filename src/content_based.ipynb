{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classifier on a single label using text_tokens as content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import twitter_preproc\n",
    "\n",
    "conf = SparkConf().setAll([\n",
    "    (\"num-executors\", 4), \n",
    "    (\"total-executor-cores\", 16), \n",
    "    (\"executor-memory\", \"8g\"),\n",
    "    (\"spark.yarn.executor.memoryOverhead\", \"64g\")])\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"///tmp/traintweet_10k.tsv\"\n",
    "user = \"engaging_user_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load DF and change Timestamp/None to 1/0 in target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "importlib.reload(twitter_preproc)\n",
    "preproc = twitter_preproc.twitter_preproc(spark, sc, datapath, method=\"CB\")\n",
    "df = preproc.getDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle BERT tokens like words, maybe TODO: find deeper meaning in the tokens(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer,NGram,CountVectorizer,IDF,StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=user, outputCol=user+\"_idx\")\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text_tokens\", outputCol=\"terms\", pattern=\"\\t\")\n",
    "cv = CountVectorizer(inputCol=\"terms\", outputCol=\"vector\")\n",
    "idf = IDF(inputCol=\"vector\", outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=[stringIndexer,regexTokenizer, cv,idf])\n",
    "\n",
    "model = pipeline.fit(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|engaging_user_id_idx|count|\n",
      "+--------------------+-----+\n",
      "|                 0.0|   12|\n",
      "|                 2.0|    9|\n",
      "|                 1.0|    9|\n",
      "|                 4.0|    7|\n",
      "|                 3.0|    7|\n",
      "|                 7.0|    6|\n",
      "|                 6.0|    6|\n",
      "|                 8.0|    6|\n",
      "|                 5.0|    6|\n",
      "|                19.0|    5|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed.select(\"features\",user+\"_idx\",target).groupBy(user+\"_idx\").count().orderBy(\"count\",ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_idx = 0.0\n",
    "user_profile = transformed.filter(transformed.engaging_user_id_idx.isin([test_user_idx]))                                                                                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+------------------------------+---------------+-----------------+\n",
      "|            features|like_timestamp|retweet_with_comment_timestamp|reply_timestamp|retweet_timestamp|\n",
      "+--------------------+--------------+------------------------------+---------------+-----------------+\n",
      "|(31642,[0,1,2,3,4...|    1581265589|                          null|           null|             null|\n",
      "|(31642,[0,3,4,5,5...|    1581083103|                          null|           null|       1581083104|\n",
      "|(31642,[0,3,4,5,1...|    1581058286|                          null|     1581058286|             null|\n",
      "|(31642,[3,4,55,59...|    1581179252|                          null|           null|             null|\n",
      "|(31642,[0,1,2,3,4...|    1581139106|                          null|           null|             null|\n",
      "|(31642,[0,2,3,4,1...|    1581257052|                          null|           null|             null|\n",
      "|(31642,[0,1,2,3,4...|    1581413344|                          null|     1581413278|             null|\n",
      "|(31642,[0,1,2,3,4...|    1581440439|                          null|           null|             null|\n",
      "|(31642,[3,4,5,43,...|    1581322301|                          null|           null|             null|\n",
      "|(31642,[0,3,4,43,...|    1581174843|                          null|           null|             null|\n",
      "|(31642,[0,3,4,26,...|    1581065283|                          null|           null|             null|\n",
      "|(31642,[0,1,2,3,4...|    1581336566|                          null|           null|             null|\n",
      "+--------------------+--------------+------------------------------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_profile.select(\"features\",\"like_timestamp\",\"retweet_with_comment_timestamp\",\"reply_timestamp\",\"retweet_timestamp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "python",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
